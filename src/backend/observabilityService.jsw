/**
 * Observability Service - System logging and tracing for Super Admin
 * Provides comprehensive visibility into system operations
 * 
 * This service uses unified dataAccess for dual-source support.
 *
 * @module backend/observabilityService
 */

import * as dataAccess from 'backend/dataAccess';
import { currentMember } from 'wix-members-backend';

// ============================================
// COLLECTION KEYS FOR DUAL-SOURCE ROUTING
// ============================================

const COLLECTION_KEYS = {
    logs: 'systemLogs',
    traces: 'systemTraces',
    errors: 'systemErrors',
    metrics: 'systemMetrics',
    alerts: 'systemAlerts',
    anomalyAlerts: 'anomalyAlerts',
    anomalyRules: 'anomalyRules',
    baselineMetrics: 'baselineMetrics',
    aiUsageLog: 'aiUsageLog'
};

// ============================================
// CONFIGURATION
// ============================================

const CONFIG = {
    // Log levels
    levels: {
        DEBUG: 0,
        INFO: 1,
        WARN: 2,
        ERROR: 3,
        CRITICAL: 4
    },
    // Log sources/services
    sources: [
        'ai-enrichment',
        'ai-router',
        'carrier-matching',
        'social-scanner',
        'ocr-service',
        'scheduler',
        'auth',
        'api',
        'database',
        'external-api',
        'system'
    ]
};

// ============================================
// AUTHORIZATION
// ============================================

async function isSuperAdmin() {
    try {
        const member = await currentMember.getMember({ fieldsets: ['FULL'] });
        if (!member) return false;
        const role = member.contactDetails?.customFields?.role || '';
        return role.toLowerCase() === 'super_admin';
    } catch (error) {
        return false;
    }
}

async function requireSuperAdmin() {
    if (!(await isSuperAdmin())) {
        throw new Error('Unauthorized: Super Admin access required');
    }
}

// ============================================
// AIRTABLE WRITE THROTTLE
// ============================================
// Only CRITICAL-level events get persisted to Airtable.
// Everything else is console-only to stay within the 50k record limit.
const PERSIST_THRESHOLD = 4; // CRITICAL = 4, ERROR = 3
let __logFailCount = 0;
const LOG_FAIL_THRESHOLD = 3;

// ============================================
// LOGGING FUNCTIONS
// ============================================

/**
 * Log an event to the system
 */
export async function log(logEntry) {
    const entry = {
        timestamp: new Date().toISOString(),
        level: logEntry.level || 'INFO',
        level_num: CONFIG.levels[logEntry.level] || 1,
        source: logEntry.source || 'system',
        message: logEntry.message || '',
        details: logEntry.details || {},
        trace_id: logEntry.traceId || generateTraceId(),
        span_id: logEntry.spanId || generateSpanId(),
        parent_span_id: logEntry.parentSpanId || null,
        user_id: logEntry.userId || null,
        session_id: logEntry.sessionId || null,
        duration: logEntry.duration || null,
        tags: Array.isArray(logEntry.tags) ? logEntry.tags.join(', ') : (logEntry.tags || '')
    };

    // Below CRITICAL threshold → console only, no Airtable write
    if (entry.level_num < PERSIST_THRESHOLD || __logFailCount >= LOG_FAIL_THRESHOLD) {
        return entry;
    }

    try {
        const errorRecord = {
            timestamp: entry.timestamp,
            level: entry.level,
            level_num: entry.level_num,
            source: entry.source,
            message: entry.message,
            details: typeof entry.details === 'object' ? JSON.stringify(entry.details) : String(entry.details),
            trace_id: entry.trace_id,
            span_id: entry.span_id,
            parent_span_id: entry.parent_span_id,
            user_id: entry.user_id,
            session_id: entry.session_id,
            duration: entry.duration,
            tags: entry.tags
        };
        await dataAccess.insertRecord(COLLECTION_KEYS.errors, errorRecord, { suppressAuth: true });
        __logFailCount = 0;
    } catch (error) {
        __logFailCount++;
        if (__logFailCount === LOG_FAIL_THRESHOLD) {
            console.warn('[Observability] Circuit breaker tripped — logging disabled');
        }
    }

    return entry;
}

/**
 * Log an AI operation
 */
export async function logAIOperation(aiLog) {
    return log({
        level: aiLog.error ? 'ERROR' : 'INFO',
        source: aiLog.source || 'ai-router',
        message: `AI ${aiLog.operation}: ${aiLog.functionId}`,
        details: aiLog,
        traceId: aiLog.traceId,
        spanId: aiLog.spanId,
        duration: aiLog.latencyMs,
        tags: ['ai', aiLog.provider, aiLog.functionId]
    });
}

/**
 * Log an external API call
 */
export async function logExternalAPI(apiLog) {
    return log({
        level: apiLog.statusCode >= 400 ? 'ERROR' : 'INFO',
        source: 'external-api',
        message: `${apiLog.method} ${apiLog.endpoint} - ${apiLog.statusCode}`,
        details: apiLog,
        traceId: apiLog.traceId,
        spanId: apiLog.spanId,
        duration: apiLog.latencyMs,
        tags: ['external-api', apiLog.service]
    });
}

/**
 * Log a database operation
 */
export async function logDatabase(dbLog) {
    // Console-only — database ops are too frequent to persist
    return { timestamp: new Date().toISOString(), level: 'DEBUG', source: 'database' };
}

// ============================================
// TRACING
// ============================================

/**
 * Start a new trace
 */
export async function startTrace(name, metadata = {}) {
    // In-memory only — no Airtable write (saves record quota)
    const traceId = generateTraceId();
    return {
        traceId,
        startSpan: (spanName) => startSpan(traceId, spanName)
    };
}

/**
 * Start a span within a trace
 */
export function startSpan(traceId, name, parentSpanId = null) {
    const spanId = generateSpanId();
    const startTime = Date.now();

    return {
        traceId,
        spanId,
        parentSpanId,
        name,
        startTime,
        end: async (status = 'success', metadata = {}) => {
            const duration = Date.now() - startTime;
            await log({
                level: status === 'error' ? 'ERROR' : 'DEBUG',
                source: 'trace',
                message: `Span: ${name}`,
                traceId,
                spanId,
                parentSpanId,
                duration,
                details: { status, ...metadata }
            });
            return { duration, status };
        }
    };
}

/**
 * End a trace
 */
export async function endTrace(traceId, status = 'completed', summary = {}) {
    // No-op — traces are in-memory only (saves record quota)
    return null;
}

// ============================================
// QUERY FUNCTIONS (Super Admin)
// ============================================

export async function getLogs(options = {}) {
    await requireSuperAdmin();

    try {
        const filters = {};
        if (options.level) filters.level = options.level;
        if (options.source) filters.service = options.source;
        
        const result = await dataAccess.queryRecords(COLLECTION_KEYS.logs, {
            filters,
            sort: [{ field: 'log_date', direction: 'desc' }],
            limit: options.limit || 50,
            skip: options.skip || 0,
            suppressAuth: true
        });

        return {
            items: result.items,
            totalCount: result.totalCount || result.items.length,
            hasMore: result.items.length === (options.limit || 50),
            page: Math.floor((options.skip || 0) / (options.limit || 50)) + 1,
            pageSize: options.limit || 50
        };
    } catch (error) {
        console.error('[Observability] Error fetching logs:', error.message);
        throw new Error('Failed to fetch logs');
    }
}

export async function getTrace(traceId) {
    await requireSuperAdmin();

    try {
        const traceRes = await dataAccess.queryRecords(COLLECTION_KEYS.traces, {
            filters: { trace_id: traceId },
            limit: 1,
            suppressAuth: true
        });

        if (!traceRes.success || traceRes.items.length === 0) {
            throw new Error('Trace not found');
        }

        const errorLogs = await dataAccess.queryRecords(COLLECTION_KEYS.errors, {
            filters: { trace_id: traceId },
            sort: [{ field: 'timestamp', direction: 'asc' }],
            limit: 100,
            suppressAuth: true
        });

        return {
            trace: traceRes.items[0],
            logs: errorLogs.items || [],
            timeline: (errorLogs.items || []).map(l => ({
                timestamp: l.timestamp,
                spanId: l.span_id,
                parentSpanId: l.parent_span_id,
                message: l.message,
                duration: l.duration,
                level: l.level
            }))
        };
    } catch (error) {
        console.error('[Observability] Error fetching trace:', error.message);
        throw new Error('Failed to fetch trace');
    }
}

export async function getErrors(options = {}) {
    await requireSuperAdmin();
    const period = options.period || 'day';
    const now = new Date();
    const start = new Date(now);
    if (period === 'hour') start.setHours(now.getHours() - 1);
    else if (period === 'week') start.setDate(now.getDate() - 7);
    else if (period === 'month') start.setDate(now.getDate() - 30);
    else start.setDate(now.getDate() - 1);

    const result = await dataAccess.queryRecords(COLLECTION_KEYS.errors, {
        filters: { timestamp: { gte: start } },
        sort: [{ field: 'timestamp', direction: 'desc' }],
        limit: options.limit || 200,
        suppressAuth: true
    });

    const items = result.items || [];
    const bySource = items.reduce((acc, item) => {
        const key = item.source || 'unknown';
        acc[key] = (acc[key] || 0) + 1;
        return acc;
    }, {});

    const byHourMap = {};
    for (const item of items) {
        const d = new Date(item.timestamp || now);
        const key = `${d.getFullYear()}-${String(d.getMonth() + 1).padStart(2, '0')}-${String(d.getDate()).padStart(2, '0')}T${String(d.getHours()).padStart(2, '0')}`;
        byHourMap[key] = (byHourMap[key] || 0) + 1;
    }
    const byHour = Object.entries(byHourMap).sort((a, b) => a[0].localeCompare(b[0])).map(([hour, count]) => ({ hour, count }));

    return { items, totalCount: items.length, bySource, byHour, period };
}

export async function getHealthMetrics(period = 'hour') {
    await requireSuperAdmin();
    const now = new Date();
    const start = new Date(now);
    if (period === 'day') start.setDate(now.getDate() - 1);
    else if (period === 'week') start.setDate(now.getDate() - 7);
    else start.setHours(now.getHours() - 1);

    const [errorsResult, tracesResult] = await Promise.all([
        dataAccess.queryRecords(COLLECTION_KEYS.errors, {
            filters: { timestamp: { gte: start } },
            limit: 500,
            suppressAuth: true
        }),
        dataAccess.queryRecords(COLLECTION_KEYS.traces, {
            filters: { timestamp: { gte: start } },
            limit: 500,
            suppressAuth: true
        })
    ]);

    const errors = errorsResult.items || [];
    const traces = tracesResult.items || [];
    const totalRequests = traces.length;
    const totalErrors = errors.length;
    const avgLatencyMs = traces.length ? Math.round(traces.reduce((sum, t) => sum + Number(t.duration || 0), 0) / traces.length) : 0;
    const errorRate = totalRequests > 0 ? Number(((totalErrors / totalRequests) * 100).toFixed(2)) : 0;

    const sourceAgg = {};
    traces.forEach((trace) => {
        const source = trace.source || 'system';
        if (!sourceAgg[source]) sourceAgg[source] = { source, requests: 0, errors: 0 };
        sourceAgg[source].requests += 1;
    });
    errors.forEach((error) => {
        const source = error.source || 'system';
        if (!sourceAgg[source]) sourceAgg[source] = { source, requests: 0, errors: 0 };
        sourceAgg[source].errors += 1;
    });

    const services = Object.values(sourceAgg).map((item) => ({
        ...item,
        errorRate: item.requests > 0 ? Number(((item.errors / item.requests) * 100).toFixed(2)) : 0,
        status: item.errors === 0 ? 'healthy' : item.errors <= 2 ? 'warning' : 'critical'
    }));

    return {
        period,
        status: errorRate > 10 ? 'critical' : errorRate > 2 ? 'warning' : 'healthy',
        totalRequests,
        totalErrors,
        errorRate,
        avgLatencyMs,
        services
    };
}

export async function getAIAnalytics(period = 'day') {
    await requireSuperAdmin();
    const now = new Date();
    const start = new Date(now);
    if (period === 'hour') start.setHours(now.getHours() - 1);
    else if (period === 'week') start.setDate(now.getDate() - 7);
    else if (period === 'month') start.setDate(now.getDate() - 30);
    else start.setDate(now.getDate() - 1);

    const result = await dataAccess.queryRecords(COLLECTION_KEYS.aiUsageLog, {
        filters: { timestamp: { gte: start } },
        limit: 2000,
        suppressAuth: true
    });

    const items = result.items || [];
    const providerMap = {};
    const functionMap = {};
    let totalTokens = 0;
    let totalLatency = 0;
    let totalRequests = 0;

    for (const item of items) {
        const provider = item.provider || 'unknown';
        const functionId = item.functionId || 'unknown';
        const tokens = Number(item.tokensUsed || 0);
        const latency = Number(item.latencyMs || 0);

        totalTokens += tokens;
        totalLatency += latency;
        totalRequests += 1;

        if (!providerMap[provider]) providerMap[provider] = { provider, requests: 0, tokens: 0, cost: 0, avgLatency: 0, latencyTotal: 0 };
        providerMap[provider].requests += 1;
        providerMap[provider].tokens += tokens;
        providerMap[provider].cost += tokens * 0.000002;
        providerMap[provider].latencyTotal += latency;

        if (!functionMap[functionId]) functionMap[functionId] = { functionId, requests: 0, tokens: 0, cost: 0, avgLatency: 0, latencyTotal: 0 };
        functionMap[functionId].requests += 1;
        functionMap[functionId].tokens += tokens;
        functionMap[functionId].cost += tokens * 0.000002;
        functionMap[functionId].latencyTotal += latency;
    }

    const byProvider = Object.values(providerMap).map((item) => ({
        provider: item.provider,
        requests: item.requests,
        tokens: item.tokens,
        cost: Number(item.cost.toFixed(4)),
        avgLatency: item.requests ? Math.round(item.latencyTotal / item.requests) : 0
    }));

    const byFunction = Object.values(functionMap).map((item) => ({
        functionId: item.functionId,
        requests: item.requests,
        tokens: item.tokens,
        cost: Number(item.cost.toFixed(4)),
        avgLatency: item.requests ? Math.round(item.latencyTotal / item.requests) : 0
    }));

    return {
        period,
        summary: {
            totalRequests,
            totalTokens,
            totalCost: Number((totalTokens * 0.000002).toFixed(4)),
            avgLatency: totalRequests ? Math.round(totalLatency / totalRequests) : 0
        },
        byProvider,
        byFunction
    };
}

export async function getLogMetadata() {
    await requireSuperAdmin();
    return {
        levels: Object.keys(CONFIG.levels),
        sources: CONFIG.sources
    };
}

// ============================================
// ANOMALY DETECTION (Phase 2)
// ============================================

const DEFAULT_ANOMALY_RULES = [
    { name: 'API Error Spike', type: 'error_spike', metric: 'errors', condition: 'stddev_gt', threshold: 2, windowMinutes: 15, severity: 'critical', enabled: true, cooldownMinutes: 15, notifyEmail: true, notifyDashboard: true },
    { name: 'Latency Drift', type: 'latency_drift', metric: 'latency', condition: 'ratio_gt', threshold: 3, windowMinutes: 60, severity: 'warning', enabled: true, cooldownMinutes: 30, notifyEmail: false, notifyDashboard: true },
    { name: 'Cost Spike', type: 'cost_spike', metric: 'ai_cost', condition: 'ratio_gt', threshold: 1.5, windowMinutes: 60, severity: 'warning', enabled: true, cooldownMinutes: 30, notifyEmail: false, notifyDashboard: true },
    { name: 'Traffic Drop', type: 'traffic_drop', metric: 'requests', condition: 'ratio_lt', threshold: 0.5, windowMinutes: 30, severity: 'info', enabled: true, cooldownMinutes: 20, notifyEmail: false, notifyDashboard: true },
    { name: 'Job Failure', type: 'job_failure', metric: 'scheduler_runs', condition: 'missing_run', threshold: 1, windowMinutes: 10, severity: 'critical', enabled: true, cooldownMinutes: 10, notifyEmail: true, notifyDashboard: true }
];

export async function getAnomalyRules() {
    await requireSuperAdmin();
    const result = await dataAccess.queryRecords(COLLECTION_KEYS.anomalyRules, {
        sort: [{ field: 'name', direction: 'asc' }],
        limit: 200,
        suppressAuth: true
    });

    if ((result.items || []).length > 0) return result.items;

    return DEFAULT_ANOMALY_RULES;
}

export async function createAnomalyRule(rule) {
    await requireSuperAdmin();
    const payload = { ...rule, enabled: rule.enabled !== false, createdAt: new Date(), updatedAt: new Date() };
    return dataAccess.insertRecord(COLLECTION_KEYS.anomalyRules, payload, { suppressAuth: true });
}

export async function updateAnomalyRule(ruleId, updates) {
    await requireSuperAdmin();
    const existing = await dataAccess.getRecord(COLLECTION_KEYS.anomalyRules, ruleId, { suppressAuth: true });
    if (!existing) throw new Error('Rule not found');
    return dataAccess.updateRecord(COLLECTION_KEYS.anomalyRules, { ...existing, ...updates, _id: ruleId, updatedAt: new Date() }, { suppressAuth: true });
}

export async function deleteAnomalyRule(ruleId) {
    await requireSuperAdmin();
    return dataAccess.removeRecord(COLLECTION_KEYS.anomalyRules, ruleId, { suppressAuth: true });
}

export async function getActiveAnomalies(options = {}) {
    await requireSuperAdmin();
    const filters = { resolvedAt: { isEmpty: true } };
    if (options.severity) filters.severity = options.severity;
    if (options.type) filters.type = options.type;
    if (options.acknowledged !== undefined) filters.acknowledged = !!options.acknowledged;

    const result = await dataAccess.queryRecords(COLLECTION_KEYS.anomalyAlerts, {
        filters,
        sort: [{ field: 'detectedAt', direction: 'desc' }],
        limit: options.limit || 100,
        suppressAuth: true
    });
    return result.items || [];
}

export async function acknowledgeAnomaly(alertId) {
    await requireSuperAdmin();
    const existing = await dataAccess.getRecord(COLLECTION_KEYS.anomalyAlerts, alertId, { suppressAuth: true });
    if (!existing) throw new Error('Alert not found');
    return dataAccess.updateRecord(COLLECTION_KEYS.anomalyAlerts, {
        ...existing,
        _id: alertId,
        acknowledged: true,
        acknowledgedAt: new Date()
    }, { suppressAuth: true });
}

export async function resolveAnomaly(alertId, notes = '') {
    await requireSuperAdmin();
    const existing = await dataAccess.getRecord(COLLECTION_KEYS.anomalyAlerts, alertId, { suppressAuth: true });
    if (!existing) throw new Error('Alert not found');
    return dataAccess.updateRecord(COLLECTION_KEYS.anomalyAlerts, {
        ...existing,
        _id: alertId,
        resolvedAt: new Date(),
        resolutionNotes: notes,
        acknowledged: true
    }, { suppressAuth: true });
}

export async function getAnomalyHistory(period = 'week') {
    await requireSuperAdmin();
    const now = new Date();
    const start = new Date(now);
    if (period === 'day') start.setDate(now.getDate() - 1);
    else if (period === 'month') start.setDate(now.getDate() - 30);
    else start.setDate(now.getDate() - 7);

    const result = await dataAccess.queryRecords(COLLECTION_KEYS.anomalyAlerts, {
        filters: { detectedAt: { gte: start } },
        limit: 1000,
        suppressAuth: true
    });
    return result.items || [];
}

export async function calculateBaseline(metric, windowDays = 14) {
    await requireSuperAdmin();
    const now = new Date();
    const start = new Date(now);
    start.setDate(now.getDate() - windowDays);
    const sourceKey = metric === 'latency' ? COLLECTION_KEYS.traces : COLLECTION_KEYS.errors;
    const fieldName = metric === 'latency' ? 'duration' : '_id';

    const result = await dataAccess.queryRecords(sourceKey, {
        filters: { timestamp: { gte: start } },
        limit: 2000,
        suppressAuth: true
    });
    const items = result.items || [];
    const values = items.map((item) => metric === 'latency' ? Number(item[fieldName] || 0) : 1);
    const mean = values.length ? values.reduce((sum, value) => sum + value, 0) / values.length : 0;
    const variance = values.length ? values.reduce((sum, value) => sum + ((value - mean) ** 2), 0) / values.length : 0;
    const stdDev = Math.sqrt(variance);

    return { metric, mean, stdDev, sampleCount: values.length, windowDays };
}

export async function updateBaselines() {
    const metrics = ['errors', 'latency'];
    const now = new Date();
    const updates = [];
    for (const metric of metrics) {
        const baseline = await calculateBaseline(metric, 14);
        const payload = {
            metric,
            source: 'system',
            hourOfDay: now.getHours(),
            dayOfWeek: now.getDay(),
            mean: Number(baseline.mean.toFixed(4)),
            stdDev: Number(baseline.stdDev.toFixed(4)),
            sampleCount: baseline.sampleCount,
            lastUpdated: now
        };
        updates.push(await dataAccess.insertRecord(COLLECTION_KEYS.baselineMetrics, payload, { suppressAuth: true }));
    }
    return { success: true, updated: updates.length };
}

export async function runAnomalyDetection() {
    const rules = await getAnomalyRules();
    const activeRules = (rules || []).filter((rule) => rule.enabled !== false);
    const now = new Date();
    const generated = [];

    for (const rule of activeRules) {
        const windowStart = new Date(now);
        windowStart.setMinutes(now.getMinutes() - Number(rule.windowMinutes || 15));

        const recentAlerts = await dataAccess.queryRecords(COLLECTION_KEYS.anomalyAlerts, {
            filters: {
                type: rule.type,
                detectedAt: { gte: new Date(now.getTime() - Number(rule.cooldownMinutes || 15) * 60 * 1000) }
            },
            limit: 1,
            suppressAuth: true
        });
        if ((recentAlerts.items || []).length > 0) continue;

        let triggered = false;
        let actualValue = 0;
        let expectedValue = 0;

        if (rule.type === 'error_spike') {
            const baseline = await calculateBaseline('errors', 14);
            const errors = await dataAccess.queryRecords(COLLECTION_KEYS.errors, {
                filters: { timestamp: { gte: windowStart } },
                limit: 1000,
                suppressAuth: true
            });
            actualValue = (errors.items || []).length;
            expectedValue = baseline.mean + (Number(rule.threshold || 2) * baseline.stdDev);
            triggered = actualValue > expectedValue && expectedValue > 0;
        } else if (rule.type === 'latency_drift') {
            const baseline = await calculateBaseline('latency', 14);
            const traces = await dataAccess.queryRecords(COLLECTION_KEYS.traces, {
                filters: { timestamp: { gte: windowStart } },
                limit: 1000,
                suppressAuth: true
            });
            const latencies = (traces.items || []).map((item) => Number(item.duration || 0)).filter((value) => value > 0);
            actualValue = latencies.length ? (latencies.reduce((sum, value) => sum + value, 0) / latencies.length) : 0;
            expectedValue = baseline.mean * Number(rule.threshold || 3);
            triggered = actualValue > expectedValue && expectedValue > 0;
        } else if (rule.type === 'traffic_drop') {
            const traces = await dataAccess.queryRecords(COLLECTION_KEYS.traces, {
                filters: { timestamp: { gte: windowStart } },
                limit: 1000,
                suppressAuth: true
            });
            const priorStart = new Date(windowStart);
            priorStart.setMinutes(priorStart.getMinutes() - Number(rule.windowMinutes || 30));
            const prior = await dataAccess.queryRecords(COLLECTION_KEYS.traces, {
                filters: { timestamp: { gte: priorStart, lt: windowStart } },
                limit: 1000,
                suppressAuth: true
            });
            actualValue = (traces.items || []).length;
            const priorCount = (prior.items || []).length;
            expectedValue = priorCount * Number(rule.threshold || 0.5);
            triggered = priorCount > 0 && actualValue < expectedValue;
        } else if (rule.type === 'cost_spike') {
            const usage = await dataAccess.queryRecords(COLLECTION_KEYS.aiUsageLog, {
                filters: { timestamp: { gte: windowStart } },
                limit: 1000,
                suppressAuth: true
            });
            actualValue = (usage.items || []).reduce((sum, item) => sum + Number(item.tokensUsed || 0), 0);
            const baseline = await calculateBaseline('errors', 14);
            expectedValue = Math.max(1, baseline.sampleCount) * Number(rule.threshold || 1.5);
            triggered = actualValue > expectedValue;
        } else if (rule.type === 'job_failure') {
            const alerts = await dataAccess.queryRecords(COLLECTION_KEYS.alerts, {
                filters: { status: 'error', timestamp: { gte: windowStart } },
                limit: 100,
                suppressAuth: true
            });
            actualValue = (alerts.items || []).length;
            expectedValue = 0;
            triggered = actualValue > 0;
        }

        if (triggered) {
            const deviation = expectedValue > 0 ? Number(((actualValue - expectedValue) / expectedValue).toFixed(4)) : 1;
            const alert = await dataAccess.insertRecord(COLLECTION_KEYS.anomalyAlerts, {
                type: rule.type,
                severity: rule.severity || 'warning',
                source: rule.source || 'system',
                metric: rule.metric,
                expectedValue,
                actualValue,
                deviation,
                message: `${rule.name} detected`,
                detectedAt: now,
                acknowledged: false,
                autoResolved: false
            }, { suppressAuth: true });
            generated.push(alert);
        }
    }

    await autoResolveAnomalies();
    await escalateCriticalAnomalies();
    return { success: true, triggered: generated.length };
}

async function autoResolveAnomalies() {
    const active = await dataAccess.queryRecords(COLLECTION_KEYS.anomalyAlerts, {
        filters: { resolvedAt: { isEmpty: true } },
        limit: 200,
        suppressAuth: true
    });
    const now = new Date();
    for (const alert of (active.items || [])) {
        if (Number(alert.deviation || 0) < 0.05) {
            await dataAccess.updateRecord(COLLECTION_KEYS.anomalyAlerts, {
                ...alert,
                _id: alert._id,
                autoResolved: true,
                resolvedAt: now
            }, { suppressAuth: true });
        }
    }
}

async function escalateCriticalAnomalies() {
    const threshold = new Date(Date.now() - 15 * 60 * 1000);
    const result = await dataAccess.queryRecords(COLLECTION_KEYS.anomalyAlerts, {
        filters: {
            severity: 'critical',
            acknowledged: false,
            detectedAt: { lte: threshold },
            resolvedAt: { isEmpty: true }
        },
        limit: 100,
        suppressAuth: true
    });

    for (const alert of (result.items || [])) {
        await dataAccess.updateRecord(COLLECTION_KEYS.anomalyAlerts, {
            ...alert,
            _id: alert._id,
            escalated: true,
            escalatedAt: new Date()
        }, { suppressAuth: true });
    }
}

// ============================================
// HELPER FUNCTIONS
// ============================================

function generateTraceId() {
    return 'tr_' + Date.now().toString(36) + Math.random().toString(36).substr(2, 9);
}

function generateSpanId() {
    return 'sp_' + Math.random().toString(36).substr(2, 12);
}
