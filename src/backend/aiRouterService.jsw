/**
 * AI Router Service - LLM-Agnostic Provider Management
 *
 * This service enables administrators to configure which AI provider
 * handles each function in the system. Supports hot-swapping providers
 * based on speed, quality, cost, or specific use case requirements.
 *
 * Current Integrations:
 * - Claude (Anthropic) - Synthesis, reasoning, safety-focused responses
 * - Gemini (Google) - OCR, multimodal processing
 * - OpenAI - General purpose, embeddings
 * - Groq - Ultra-fast inference for real-time needs
 * - Mistral - European alternative, good for certain tasks
 */

import { getSecret } from 'wix-secrets-backend';
import { fetch } from 'wix-fetch';
import { currentMember } from 'wix-members-backend';
import { log, logAIOperation, startTrace, endTrace } from 'backend/observabilityService';
import * as dataAccess from 'backend/dataAccess';

// ============================================
// CONFIGURATION & CONSTANTS
// ============================================

const CONFIG = {
    cacheExpiry: 5 * 60 * 1000, // 5 minutes cache for config
    providerCostMetricsCacheExpiry: 5 * 60 * 1000
};

// Collection keys for dataAccess routing
const COLLECTION_KEYS = {
    routerConfig: 'aiRouterConfig',
    usageLog: 'aiUsageLog',
    auditLog: 'auditLog',
    providerCosts: 'aiProviderCosts',
    optimizerConfig: 'costOptimizerConfig'
};

// In-memory cache for router config
let configCache = null;
let configCacheTime = 0;
let providerCostMetricsCache = null;
let providerCostMetricsCacheTime = 0;

// ============================================
// PROVIDER REGISTRY
// ============================================

/**
 * Complete registry of all supported AI providers
 * Each provider has models, endpoints, capabilities, and characteristics
 */
const PROVIDER_REGISTRY = {
    anthropic: {
        name: 'Anthropic (Claude)',
        description: 'Advanced reasoning, safety-focused, excellent for synthesis',
        secretKey: 'CLAUDE_API_KEY',
        endpoint: 'https://api.anthropic.com/v1/messages',
        models: [
            { id: 'claude-sonnet-4-20250514', name: 'Claude Sonnet 4', tier: 'standard', speed: 'medium', quality: 'high' },
            { id: 'claude-3-5-sonnet-20241022', name: 'Claude 3.5 Sonnet', tier: 'standard', speed: 'medium', quality: 'high' },
            { id: 'claude-3-haiku-20240307', name: 'Claude 3 Haiku', tier: 'fast', speed: 'fast', quality: 'good' },
            { id: 'claude-3-opus-20240229', name: 'Claude 3 Opus', tier: 'premium', speed: 'slow', quality: 'highest' }
        ],
        capabilities: ['synthesis', 'reasoning', 'analysis', 'chat', 'code', 'safety'],
        characteristics: {
            latency: 'medium',
            costTier: 'premium',
            contextWindow: 200000,
            strengths: ['Complex reasoning', 'Safety', 'Following instructions', 'Long context']
        }
    },

    openai: {
        name: 'OpenAI',
        description: 'Industry standard, broad capabilities, strong ecosystem',
        secretKey: 'OPENAI_API_KEY',
        endpoint: 'https://api.openai.com/v1/chat/completions',
        models: [
            { id: 'gpt-4o', name: 'GPT-4o', tier: 'standard', speed: 'medium', quality: 'high' },
            { id: 'gpt-4o-mini', name: 'GPT-4o Mini', tier: 'fast', speed: 'fast', quality: 'good' },
            { id: 'gpt-4-turbo', name: 'GPT-4 Turbo', tier: 'premium', speed: 'medium', quality: 'high' },
            { id: 'gpt-3.5-turbo', name: 'GPT-3.5 Turbo', tier: 'economy', speed: 'fast', quality: 'standard' }
        ],
        capabilities: ['synthesis', 'reasoning', 'chat', 'code', 'embeddings', 'vision', 'analysis'],
        characteristics: {
            latency: 'medium',
            costTier: 'standard',
            contextWindow: 128000,
            strengths: ['General purpose', 'Code generation', 'Ecosystem integration']
        }
    },

    groq: {
        name: 'Groq',
        description: 'Ultra-fast inference. groq/compound and groq/compound-mini have no daily token limit — preferred for high-volume research and synthesis.',
        secretKey: 'GROQ_API_KEY',
        endpoint: 'https://api.groq.com/openai/v1/chat/completions',
        models: [
            // --- Unlimited token models (preferred for web_research, social_scanning) ---
            { id: 'groq/compound',                                   name: 'Groq Compound',           tier: 'premium',  speed: 'ultra-fast', quality: 'highest' },
            { id: 'groq/compound-mini',                              name: 'Groq Compound Mini',      tier: 'standard', speed: 'ultra-fast', quality: 'high'    },
            // --- Llama 4 series ---
            { id: 'meta-llama/llama-4-maverick-17b-128e-instruct',   name: 'Llama 4 Maverick 17B',   tier: 'standard', speed: 'ultra-fast', quality: 'high'  },
            { id: 'meta-llama/llama-4-scout-17b-16e-instruct',       name: 'Llama 4 Scout 17B',      tier: 'fast',     speed: 'ultra-fast', quality: 'good'  },
            // --- Llama 3 series (keep) ---
            { id: 'llama-3.3-70b-versatile',                         name: 'Llama 3.3 70B',          tier: 'standard', speed: 'ultra-fast', quality: 'high'  },
            { id: 'llama-3.1-8b-instant',                            name: 'Llama 3.1 8B Instant',   tier: 'fast',     speed: 'ultra-fast', quality: 'good'  },
            // --- Premium reasoning ---
            { id: 'moonshotai/kimi-k2-instruct',                     name: 'Kimi K2',                tier: 'premium',  speed: 'fast',       quality: 'high'  },
            { id: 'qwen/qwen3-32b',                                  name: 'Qwen3 32B',              tier: 'standard', speed: 'fast',       quality: 'high'  },
            // --- OSS large models ---
            { id: 'openai/gpt-oss-120b',                             name: 'GPT-OSS 120B',           tier: 'premium',  speed: 'medium',     quality: 'highest' },
            { id: 'openai/gpt-oss-20b',                              name: 'GPT-OSS 20B',            tier: 'fast',     speed: 'fast',       quality: 'good'  },
            // --- Safety/guard models (role: 'guard' — for input filtering only, not generation) ---
            { id: 'meta-llama/llama-guard-4-12b',                    name: 'Llama Guard 4 12B',      tier: 'fast',     speed: 'fast',       quality: 'good',  role: 'guard' },
            { id: 'meta-llama/llama-prompt-guard-2-22m',             name: 'Prompt Guard 2 22M',     tier: 'fast',     speed: 'instant',    quality: 'good',  role: 'guard' },
            { id: 'meta-llama/llama-prompt-guard-2-86m',             name: 'Prompt Guard 2 86M',     tier: 'fast',     speed: 'instant',    quality: 'good',  role: 'guard' },
            { id: 'openai/gpt-oss-safeguard-20b',                    name: 'GPT-OSS Safeguard 20B',  tier: 'fast',     speed: 'fast',       quality: 'good',  role: 'guard' }
        ],
        capabilities: ['chat', 'reasoning', 'analysis', 'real-time', 'synthesis', 'research'],
        characteristics: {
            latency: 'ultra-low',
            costTier: 'economy',
            contextWindow: 128000,
            unlimitedTokenModels: ['groq/compound', 'groq/compound-mini'],
            strengths: ['Speed', 'Unlimited-token compound models', 'Real-time responses', 'Cost efficiency']
        }
    },

    google: {
        name: 'Google (Gemini)',
        description: 'Multimodal excellence, strong at OCR and vision tasks',
        secretKey: 'GEMINI_API_KEY',
        endpoint: 'https://generativelanguage.googleapis.com/v1beta/models',
        models: [
            // Stable production models (GA since June 2025)
            { id: 'gemini-2.5-pro',         name: 'Gemini 2.5 Pro',           tier: 'premium',      speed: 'medium', quality: 'highest' },
            { id: 'gemini-2.5-flash',       name: 'Gemini 2.5 Flash',         tier: 'standard',     speed: 'fast',   quality: 'high'    },
            { id: 'gemini-2.5-flash-lite',  name: 'Gemini 2.5 Flash Lite',    tier: 'economy',      speed: 'fast',   quality: 'good'    },
            // Preview — functional but subject to 2-week shutdown notice; not used as default
            { id: 'gemini-3.1-pro-preview', name: 'Gemini 3.1 Pro (Preview)', tier: 'experimental', speed: 'medium', quality: 'highest', preview: true }
        ],
        capabilities: ['ocr', 'vision', 'multimodal', 'reasoning', 'code', 'synthesis', 'analysis'],
        characteristics: {
            latency: 'low',
            costTier: 'economy',
            contextWindow: 1000000,
            strengths: ['OCR', 'Vision', 'Multimodal', 'Long context (1M tokens)', 'Stable 2.5 series']
        }
    },

    mistral: {
        name: 'Mistral AI',
        description: 'European provider, strong multilingual and code capabilities',
        secretKey: 'MISTRAL_API_KEY',
        endpoint: 'https://api.mistral.ai/v1/chat/completions',
        models: [
            { id: 'mistral-large-latest', name: 'Mistral Large', tier: 'premium', speed: 'medium', quality: 'high' },
            { id: 'mistral-medium-latest', name: 'Mistral Medium', tier: 'standard', speed: 'fast', quality: 'good' },
            { id: 'mistral-small-latest', name: 'Mistral Small', tier: 'economy', speed: 'fast', quality: 'standard' },
            { id: 'codestral-latest', name: 'Codestral', tier: 'standard', speed: 'fast', quality: 'high' }
        ],
        capabilities: ['chat', 'code', 'reasoning', 'multilingual'],
        characteristics: {
            latency: 'low',
            costTier: 'standard',
            contextWindow: 32000,
            strengths: ['Code', 'Multilingual', 'European data residency']
        }
    },

    cohere: {
        name: 'Cohere',
        description: 'Enterprise-focused, excellent embeddings and RAG',
        secretKey: 'COHERE_API_KEY',
        endpoint: 'https://api.cohere.ai/v1/chat',
        models: [
            { id: 'command-r-plus', name: 'Command R+', tier: 'premium', speed: 'medium', quality: 'high' },
            { id: 'command-r', name: 'Command R', tier: 'standard', speed: 'fast', quality: 'good' },
            { id: 'command-light', name: 'Command Light', tier: 'economy', speed: 'fast', quality: 'standard' }
        ],
        capabilities: ['chat', 'rag', 'embeddings', 'rerank', 'enterprise'],
        characteristics: {
            latency: 'medium',
            costTier: 'standard',
            contextWindow: 128000,
            strengths: ['RAG', 'Embeddings', 'Enterprise features', 'Reranking']
        }
    }
};

// ============================================
// FUNCTION CATEGORIES
// ============================================

/**
 * All AI functions in the system that can be routed
 */
const FUNCTION_REGISTRY = {
    // Core Enrichment
    carrier_synthesis: {
        name: 'Carrier Data Synthesis',
        description: 'Synthesizes carrier information into structured enrichment data',
        currentProvider: 'anthropic',
        currentModel: 'claude-sonnet-4-20250514',
        recommendedProviders: ['anthropic', 'openai'],
        requirements: ['synthesis', 'reasoning'],
        priority: 'quality',
        category: 'enrichment'
    },

    web_research: {
        name: 'Web Research',
        description: 'Fetches real-time information about carriers from the web',
        currentProvider: 'perplexity',
        currentModel: 'sonar-pro',
        recommendedProviders: ['groq'],
        requirements: ['research', 'web-search'],
        priority: 'accuracy',
        category: 'research'
    },

    social_scanning: {
        name: 'Social Media Scanning',
        description: 'Scans Reddit, forums, and social media for driver sentiment',
        currentProvider: 'perplexity',
        currentModel: 'sonar-pro',
        recommendedProviders: ['groq'],
        requirements: ['research', 'real-time-info'],
        priority: 'depth',
        category: 'research'
    },

    // Document Processing
    document_ocr: {
        name: 'Document OCR',
        description: 'Extracts text and data from CDL, med cards, and other documents',
        currentProvider: 'google',
        currentModel: 'gemini-2.5-flash',
        recommendedProviders: ['google', 'openai'],
        requirements: ['ocr', 'vision'],
        priority: 'accuracy',
        category: 'documents'
    },

    // Real-time Functions
    quick_classification: {
        name: 'Quick Classification',
        description: 'Fast classification of driver queries or document types',
        currentProvider: 'groq',
        currentModel: 'llama-3.3-70b-versatile',
        recommendedProviders: ['groq', 'anthropic'],
        requirements: ['chat'],
        priority: 'speed',
        category: 'real-time'
    },

    sentiment_analysis: {
        name: 'Sentiment Analysis',
        description: 'Analyzes driver reviews and feedback sentiment',
        currentProvider: 'groq',
        currentModel: 'llama-3.3-70b-versatile',
        recommendedProviders: ['groq', 'anthropic', 'openai'],
        requirements: ['analysis'],
        priority: 'speed',
        category: 'analysis'
    },

    // Chat & Support
    driver_chat: {
        name: 'Driver Chat Assistant',
        description: 'Handles driver questions and support conversations',
        currentProvider: 'anthropic',
        currentModel: 'claude-3-haiku-20240307',
        recommendedProviders: ['google', 'anthropic', 'groq'],
        requirements: ['chat', 'safety'],
        priority: 'balanced',
        category: 'chat'
    },

    admin_assistant: {
        name: 'Admin Assistant',
        description: 'Helps administrators with queries and data analysis',
        currentProvider: 'anthropic',
        currentModel: 'claude-sonnet-4-20250514',
        recommendedProviders: ['anthropic', 'openai'],
        requirements: ['reasoning', 'analysis'],
        priority: 'quality',
        category: 'chat'
    },

    // Data Processing
    data_extraction: {
        name: 'Data Extraction',
        description: 'Extracts structured data from unstructured text',
        currentProvider: 'anthropic',
        currentModel: 'claude-3-haiku-20240307',
        recommendedProviders: ['anthropic', 'openai', 'mistral'],
        requirements: ['reasoning'],
        priority: 'accuracy',
        category: 'processing'
    },

    translation: {
        name: 'Translation',
        description: 'Translates content for multilingual support',
        currentProvider: 'mistral',
        currentModel: 'mistral-large-latest',
        recommendedProviders: ['mistral', 'openai', 'google'],
        requirements: ['multilingual'],
        priority: 'quality',
        category: 'processing'
    },

    // Embeddings & Search
    embeddings: {
        name: 'Text Embeddings',
        description: 'Generates embeddings for semantic search',
        currentProvider: 'openai',
        currentModel: 'text-embedding-3-small',
        recommendedProviders: ['openai', 'cohere'],
        requirements: ['embeddings'],
        priority: 'quality',
        category: 'search'
    },

    // Agent Orchestration — PINNED to Anthropic (requires contentBlocks/stopReason for tool_use loop)
    agent_orchestration: {
        name: 'Agent Orchestration',
        description: 'Agentic tool-use loop for multi-step tasks across all surfaces',
        currentProvider: 'anthropic',
        currentModel: 'claude-sonnet-4-20250514',
        recommendedProviders: ['anthropic'],
        requirements: ['reasoning', 'chat'],
        priority: 'quality',
        category: 'agent',
        pinned: true
    }
};

// ============================================
// AUTHORIZATION
// ============================================

async function isAdmin() {
    try {
        const member = await currentMember.getMember({ fieldsets: ['FULL'] });
        if (!member) return false;

        const adminRoles = ['admin', 'super_admin', 'ops_admin'];
        const memberRole = member.contactDetails?.customFields?.role || '';

        return adminRoles.includes(memberRole.toLowerCase());
    } catch (error) {
        console.error('Admin check failed:', error);
        return false;
    }
}

async function requireAdmin() {
    const authorized = await isAdmin();
    if (!authorized) {
        throw new Error('Unauthorized: Admin access required');
    }
}

async function isSuperAdmin() {
    try {
        const member = await currentMember.getMember({ fieldsets: ['FULL'] });
        if (!member) return false;

        const memberRole = member.contactDetails?.customFields?.role || '';
        return memberRole.toLowerCase() === 'super_admin';
    } catch (error) {
        return false;
    }
}

// ============================================
// ROUTER CONFIGURATION
// ============================================

/**
 * Get current router configuration
 * Returns cached config if fresh, otherwise fetches from database
 */
export async function getRouterConfig() {
    await requireAdmin();

    // Check cache
    if (configCache && (Date.now() - configCacheTime) < CONFIG.cacheExpiry) {
        return configCache;
    }

    try {
        const result = await dataAccess.queryRecords(COLLECTION_KEYS.routerConfig, {
            limit: 100,
            suppressAuth: true
        });

        // Build config map
        const configMap = {};
        for (const item of (result.items || [])) {
            configMap[item.functionId] = {
                provider: item.provider,
                model: item.model,
                enabled: item.enabled !== false,
                fallbackProvider: item.fallbackProvider,
                fallbackModel: item.fallbackModel,
                customSettings: item.customSettings || {},
                lastModified: item._updatedDate
            };
        }

        // Merge with defaults from FUNCTION_REGISTRY
        const fullConfig = {};
        for (const [funcId, funcDef] of Object.entries(FUNCTION_REGISTRY)) {
            fullConfig[funcId] = {
                ...funcDef,
                provider: configMap[funcId]?.provider || funcDef.currentProvider,
                model: configMap[funcId]?.model || funcDef.currentModel,
                enabled: configMap[funcId]?.enabled !== false,
                fallbackProvider: configMap[funcId]?.fallbackProvider || null,
                fallbackModel: configMap[funcId]?.fallbackModel || null,
                customSettings: configMap[funcId]?.customSettings || {},
                isCustomized: !!configMap[funcId]
            };
        }

        // Update cache
        configCache = fullConfig;
        configCacheTime = Date.now();

        return fullConfig;

    } catch (error) {
        console.error('Error fetching router config:', error);
        // Return defaults
        return FUNCTION_REGISTRY;
    }
}

/**
 * Update configuration for a specific function
 */
export async function updateFunctionConfig(functionId, config) {
    await requireAdmin();

    if (!FUNCTION_REGISTRY[functionId]) {
        throw new Error(`Unknown function: ${functionId}`);
    }

    // Validate provider and model
    const provider = PROVIDER_REGISTRY[config.provider];
    if (!provider) {
        throw new Error(`Unknown provider: ${config.provider}`);
    }

    const validModel = provider.models.find(m => m.id === config.model);
    if (!validModel) {
        throw new Error(`Invalid model ${config.model} for provider ${config.provider}`);
    }

    try {
        // Check if config exists
        const existingResult = await dataAccess.queryRecords(COLLECTION_KEYS.routerConfig, {
            filters: { functionId: functionId },
            limit: 1,
            suppressAuth: true
        });

        const member = await currentMember.getMember();
        const configData = {
            functionId,
            provider: config.provider,
            model: config.model,
            enabled: config.enabled !== false,
            fallbackProvider: config.fallbackProvider || null,
            fallbackModel: config.fallbackModel || null,
            customSettings: config.customSettings || {},
            modifiedBy: member?.loginEmail || 'admin',
            modifiedAt: new Date()
        };

        if (existingResult.success && existingResult.items.length > 0) {
            configData._id = existingResult.items[0]._id;
            await dataAccess.updateRecord(COLLECTION_KEYS.routerConfig, configData, { suppressAuth: true });
        } else {
            await dataAccess.insertRecord(COLLECTION_KEYS.routerConfig, configData, { suppressAuth: true });
        }

        // Clear cache
        configCache = null;

        // Log to audit
        await logAuditEntry('updateAIRouterConfig', functionId, {
            provider: config.provider,
            model: config.model
        });

        return { success: true, functionId, config: configData };

    } catch (error) {
        console.error('Error updating function config:', error);
        throw new Error('Failed to update configuration');
    }
}

/**
 * Reset function to default configuration
 */
export async function resetFunctionConfig(functionId) {
    await requireAdmin();

    if (!FUNCTION_REGISTRY[functionId]) {
        throw new Error(`Unknown function: ${functionId}`);
    }

    try {
        const existingResult = await dataAccess.queryRecords(COLLECTION_KEYS.routerConfig, {
            filters: { functionId: functionId },
            limit: 1,
            suppressAuth: true
        });

        if (existingResult.success && existingResult.items.length > 0) {
            await dataAccess.removeRecord(COLLECTION_KEYS.routerConfig, existingResult.items[0]._id, { suppressAuth: true });
        }

        // Clear cache
        configCache = null;

        await logAuditEntry('resetAIRouterConfig', functionId, {
            resetTo: 'default'
        });

        return { success: true, functionId, resetToDefault: true };

    } catch (error) {
        console.error('Error resetting function config:', error);
        throw new Error('Failed to reset configuration');
    }
}

// ============================================
// PROVIDER INFORMATION
// ============================================

/**
 * Get all available providers with their capabilities
 */
export async function getProviders() {
    await requireAdmin();

    // Check which providers have API keys configured
    const providerStatus = {};

    for (const [providerId, provider] of Object.entries(PROVIDER_REGISTRY)) {
        let hasApiKey = false;
        try {
            const key = await getSecret(provider.secretKey);
            hasApiKey = !!key;
        } catch (e) {
            hasApiKey = false;
        }

        providerStatus[providerId] = {
            ...provider,
            id: providerId,
            configured: hasApiKey,
            apiKeySecret: provider.secretKey // So admin knows which secret to set
        };
    }

    return providerStatus;
}

/**
 * Get all function definitions
 */
export async function getFunctions() {
    await requireAdmin();

    return Object.entries(FUNCTION_REGISTRY).map(([id, func]) => ({
        id,
        ...func
    }));
}

/**
 * Get models for a specific provider
 */
export async function getProviderModels(providerId) {
    await requireAdmin();

    const provider = PROVIDER_REGISTRY[providerId];
    if (!provider) {
        throw new Error(`Unknown provider: ${providerId}`);
    }

    return provider.models;
}

// ============================================
// USAGE STATISTICS
// ============================================

/**
 * Get AI usage statistics
 */
export async function getUsageStats(period = 'week') {
    await requireAdmin();

    try {
        const now = new Date();
        const startDate = period === 'month'
            ? new Date(now.getTime() - 30 * 24 * 60 * 60 * 1000)
            : new Date(now.getTime() - 7 * 24 * 60 * 60 * 1000);

        const result = await dataAccess.queryRecords(COLLECTION_KEYS.usageLog, {
            filters: { timestamp: { gte: startDate } },
            limit: 1000,
            suppressAuth: true
        });

        // Aggregate by function and provider
        const byFunction = {};
        const byProvider = {};
        let totalCalls = 0;
        let totalTokens = 0;
        let totalLatency = 0;
        let errorCount = 0;

        for (const logItem of (result.items || [])) {
            totalCalls++;
            totalTokens += logItem.tokensUsed || 0;
            totalLatency += logItem.latencyMs || 0;
            if (logItem.error) errorCount++;

            // By function
            if (!byFunction[logItem.functionId]) {
                byFunction[logItem.functionId] = { calls: 0, tokens: 0, errors: 0 };
            }
            byFunction[logItem.functionId].calls++;
            byFunction[logItem.functionId].tokens += logItem.tokensUsed || 0;
            if (logItem.error) byFunction[logItem.functionId].errors++;

            // By provider
            if (!byProvider[logItem.provider]) {
                byProvider[logItem.provider] = { calls: 0, tokens: 0, avgLatency: 0, errors: 0 };
            }
            byProvider[logItem.provider].calls++;
            byProvider[logItem.provider].tokens += logItem.tokensUsed || 0;
            if (logItem.error) byProvider[logItem.provider].errors++;
        }

        // Calculate averages
        for (const provider of Object.values(byProvider)) {
            provider.avgLatency = provider.calls > 0 ? Math.round(totalLatency / provider.calls) : 0;
        }

        return {
            period,
            totalCalls,
            totalTokens,
            avgLatency: totalCalls > 0 ? Math.round(totalLatency / totalCalls) : 0,
            errorRate: totalCalls > 0 ? Math.round((errorCount / totalCalls) * 100) : 0,
            byFunction,
            byProvider
        };

    } catch (error) {
        console.error('Error fetching usage stats:', error);
        return { period, totalCalls: 0, byFunction: {}, byProvider: {} };
    }
}

// ============================================
// CORE ROUTER FUNCTION
// ============================================

/**
 * Route an AI request to the configured provider
 * This is the main function other services will call
 */
export async function routeAIRequest(functionId, request, traceId = null) {
    const startTime = Date.now();

    // Start trace if not provided
    let localTraceId = traceId;
    let traceCreated = false;
    if (!localTraceId) {
        const trace = await startTrace('routeAIRequest', { functionId, tags: ['ai-router'] });
        localTraceId = trace.traceId;
        traceCreated = true;
    }

    await log({ level: 'INFO', source: 'ai-router', message: `Routing AI request: ${functionId}`, traceId: localTraceId });

    if (!FUNCTION_REGISTRY[functionId]) {
        await log({ level: 'ERROR', source: 'ai-router', message: `Unknown function: ${functionId}`, traceId: localTraceId });
        throw new Error(`Unknown function: ${functionId}`);
    }

    // Get current configuration
    let config;
    try {
        const fullConfig = await getRouterConfigInternal();
        config = fullConfig[functionId] || FUNCTION_REGISTRY[functionId];
    } catch (e) {
        config = FUNCTION_REGISTRY[functionId];
    }

    // ----------------------------------------------------
    // COST OPTIMIZER LOGIC (Phase 1)
    // ----------------------------------------------------
    let isOptimized = false;
    let savingsEstimate = 0;
    let optimizerFallbackQueue = [];

    try {
        // Query optimizer config (with simple in-memory check to avoid DB spam if possible, 
        // but for now we query as per plan. Optimization in Phase 4)
        const optimizerConfig = await getCostOptimizerConfig();

        if (optimizerConfig.enabled && !config.pinned) {
            const optimalCandidates = await getOptimalProviderCandidates(functionId, request, optimizerConfig);
            const optimal = optimalCandidates[0] || null;
            optimizerFallbackQueue = optimalCandidates.slice(1);

            if (optimal && (optimal.provider !== config.provider || optimal.model !== config.model)) {

                // Calculate estimated savings (per 1k tokens)
                const originalCost = await estimateRequestCost(config.provider, config.model);
                const optimalCost = await estimateRequestCost(optimal.provider, optimal.model);

                savingsEstimate = Math.max(0, originalCost - optimalCost);
                isOptimized = true;

                // Override configuration
                await log({
                    level: 'INFO',
                    source: 'ai-router',
                    message: `Optimizer: Switching ${functionId} from ${config.provider}/${config.model} to ${optimal.provider}/${optimal.model}`,
                    traceId: localTraceId,
                    details: { savingsEstimate, original: `${config.provider}/${config.model}` }
                });

                config.provider = optimal.provider;
                config.model = optimal.model;
                // Keep original custom settings unless we want to override them
            }
        }
    } catch (optError) {
        console.warn('Cost optimizer failed, using default routing:', optError);
        // Fail open - continue with default config
    }
    // ----------------------------------------------------

    if (!config.enabled) {
        await log({ level: 'WARN', source: 'ai-router', message: `Function ${functionId} is disabled`, traceId: localTraceId });
        throw new Error(`Function ${functionId} is disabled`);
    }

    const provider = PROVIDER_REGISTRY[config.provider];
    if (!provider) {
        throw new Error(`Provider ${config.provider} not found`);
    }

    let response;
    let error = null;
    let usedFallback = false;

    try {
        response = await callProvider(config.provider, config.model, request, localTraceId);
    } catch (primaryError) {
        console.error(`Primary provider ${config.provider} failed:`, primaryError.message);
        await log({ level: 'WARN', source: 'ai-router', message: `Primary provider ${config.provider} failed`, traceId: localTraceId, details: { error: primaryError.message } });

        // If optimizer is enabled, try next cheapest eligible candidates first
        if (optimizerFallbackQueue.length > 0) {
            for (const candidate of optimizerFallbackQueue) {
                try {
                    await log({
                        level: 'INFO',
                        source: 'ai-router',
                        message: `Optimizer fallback attempt ${candidate.provider}/${candidate.model}`,
                        traceId: localTraceId
                    });
                    response = await callProvider(candidate.provider, candidate.model, request, localTraceId);
                    config.provider = candidate.provider;
                    config.model = candidate.model;
                    usedFallback = true;
                    error = null;
                    break;
                } catch (candidateError) {
                    await log({
                        level: 'WARN',
                        source: 'ai-router',
                        message: `Optimizer fallback failed ${candidate.provider}/${candidate.model}`,
                        traceId: localTraceId,
                        details: { error: candidateError.message }
                    });
                }
            }
        }

        if (response) {
            // Recovered by optimizer fallback queue
        } else
        // Try fallback if configured
        if (config.fallbackProvider && config.fallbackModel) {
            try {
                console.log(`Attempting fallback to ${config.fallbackProvider}...`);
                await log({ level: 'INFO', source: 'ai-router', message: `Attempting fallback to ${config.fallbackProvider}`, traceId: localTraceId });
                response = await callProvider(config.fallbackProvider, config.fallbackModel, request, localTraceId);
                usedFallback = true;
            } catch (fallbackError) {
                error = fallbackError.message;
                await log({ level: 'ERROR', source: 'ai-router', message: `All providers failed for ${functionId}`, traceId: localTraceId, details: { primary: primaryError.message, fallback: fallbackError.message } });
                if (traceCreated) await endTrace(localTraceId, 'error', { error: 'All providers failed' });
                throw new Error(`All providers failed. Primary: ${primaryError.message}. Fallback: ${fallbackError.message}`);
            }
        } else {
            error = primaryError.message;
            if (traceCreated) await endTrace(localTraceId, 'error', { error: primaryError.message });
            throw primaryError;
        }
    }

    // Log usage with optimizer metadata
    const latency = Date.now() - startTime;
    await logUsage(functionId, config.provider, config.model, latency, response?.tokensUsed, error, usedFallback, isOptimized, savingsEstimate);

    // Log savings if applicable (custom log for analysis)
    if (isOptimized && !error) {
        // Approximate actual savings: (tokens / 1000) * savingsEstimate
        const actualSavings = (response?.tokensUsed ? (response.tokensUsed / 1000) * savingsEstimate : 0);
        if (actualSavings > 0) {
            await logAIOperation({
                source: 'cost-optimizer',
                operation: 'savings',
                functionId,
                totalTokens: response?.tokensUsed,
                details: { savings: actualSavings, provider: config.provider, model: config.model }
            });
        }
    }

    // Log successful AI operation to observability
    await logAIOperation({
        source: 'ai-router',
        operation: 'route',
        functionId,
        provider: usedFallback ? config.fallbackProvider : config.provider,
        model: usedFallback ? config.fallbackModel : config.model,
        totalTokens: response?.tokensUsed,
        latencyMs: latency,
        usedFallback,
        traceId: localTraceId
    });

    if (traceCreated) await endTrace(localTraceId, 'completed', { provider: config.provider, latency, usedFallback });

    return response;
}

/**
 * Selects the optimal provider based on configuration
 */
export async function selectOptimalProvider(functionId, request, optimizerConfig) {
    const candidates = await getOptimalProviderCandidates(functionId, request, optimizerConfig);
    return candidates[0] || null;
}

async function getOptimalProviderCandidates(functionId, request, optimizerConfig) {
    if (!optimizerConfig?.enabled) return [];

    try {
        // 1. Get requirements for function
        const funcDef = FUNCTION_REGISTRY[functionId];
        if (!funcDef) return null;

        const requirements = funcDef.requirements || [];

        // 2. Get all provider metrics
        const metrics = await getProviderCostMetrics();
        if (!metrics || metrics.length === 0) return null;

        // 3. Filter candidates
        const candidates = metrics.filter(m => {
            // Must be active and available
            if (!m.isActive) return false;

            // Must satisfy quality threshold
            if ((m.qualityScore || 0) < optimizerConfig.qualityThreshold) return false;

            // Must not be excluded
            if (optimizerConfig.excludedProviders?.includes(m.providerId)) return false;

            // Must support requirements
            const providerDef = PROVIDER_REGISTRY[m.providerId];
            if (!providerDef) return false;

            const hasCapabilities = requirements.every(req => providerDef.capabilities?.includes(req));
            if (!hasCapabilities) return false;

            // Must check max cost if set
            if (optimizerConfig.maxCostPerRequest > 0) {
                // Estimate cost: (1k input + 1k output) as rough baseline or use request tokens
                // Here using per-1k unit cost
                const estimatedUnitCost = (m.costInput || 0) + (m.costOutput || 0);
                // Assume avg request 2k tokens? 
                // Using 1 unit cost as filter proxy
                if (estimatedUnitCost > optimizerConfig.maxCostPerRequest) return false;
            }

            return true;
        });

        if (candidates.length === 0) return [];

        // 4. Sort by cost (Cheapest first)
        // Weight preferred providers?
        candidates.sort((a, b) => {
            const costA = (a.costInput || 0) + (a.costOutput || 0);
            const costB = (b.costInput || 0) + (b.costOutput || 0);

            // If preferred, artificially lower cost for sorting
            const isPrefA = optimizerConfig.preferredProviders?.includes(a.providerId);
            const isPrefB = optimizerConfig.preferredProviders?.includes(b.providerId);

            const adjCostA = isPrefA ? costA * 0.8 : costA;
            const adjCostB = isPrefB ? costB * 0.8 : costB;

            return adjCostA - adjCostB;
        });

        // Return top candidate
        return candidates.map((candidate) => ({
            provider: candidate.providerId,
            model: candidate.modelId
        }));

    } catch (e) {
        console.error('Error in selectOptimalProvider:', e);
        return []; // Fallback to default
    }
}

/**
 * Estimate cost for a specific provider/model (per 1k tokens proxy)
 */
async function estimateRequestCost(providerId, modelId) {
    try {
        const metrics = await getProviderCostMetrics();
        const metric = metrics.find(m => m.providerId === providerId && m.modelId === modelId);
        if (metric) {
            return (metric.costInput || 0) + (metric.costOutput || 0);
        }
        return 0;
    } catch (e) {
        return 0;
    }
}

/**
 * Internal config getter (no auth check for internal use)
 */
async function getRouterConfigInternal() {
    if (configCache && (Date.now() - configCacheTime) < CONFIG.cacheExpiry) {
        return configCache;
    }

    try {
        const result = await dataAccess.queryRecords(COLLECTION_KEYS.routerConfig, {
            limit: 100,
            suppressAuth: true
        });

        const configMap = {};
        for (const item of (result.items || [])) {
            configMap[item.functionId] = {
                provider: item.provider,
                model: item.model,
                enabled: item.enabled !== false,
                fallbackProvider: item.fallbackProvider,
                fallbackModel: item.fallbackModel
            };
        }

        const fullConfig = {};
        for (const [funcId, funcDef] of Object.entries(FUNCTION_REGISTRY)) {
            fullConfig[funcId] = {
                ...funcDef,
                provider: configMap[funcId]?.provider || funcDef.currentProvider,
                model: configMap[funcId]?.model || funcDef.currentModel,
                enabled: configMap[funcId]?.enabled !== false,
                fallbackProvider: configMap[funcId]?.fallbackProvider,
                fallbackModel: configMap[funcId]?.fallbackModel
            };
        }

        configCache = fullConfig;
        configCacheTime = Date.now();

        return fullConfig;
    } catch (e) {
        return FUNCTION_REGISTRY;
    }
}

/**
 * Call a specific provider
 */
async function callProvider(providerId, modelId, request, traceId = null) {
    const provider = PROVIDER_REGISTRY[providerId];
    if (!provider) {
        throw new Error(`Unknown provider: ${providerId}`);
    }

    const apiKey = await getSecret(provider.secretKey);
    if (!apiKey) {
        throw new Error(`API key not configured for ${providerId}. Set secret: ${provider.secretKey}`);
    }

    const callStartTime = Date.now();
    let result;

    // Provider-specific request formatting
    switch (providerId) {
        case 'anthropic':
            result = await callAnthropic(apiKey, modelId, request);
            break;
        case 'openai':
        case 'groq':
            result = await callOpenAICompatible(provider.endpoint, apiKey, modelId, request);
            break;
        case 'google':
            result = await callGemini(apiKey, modelId, request);
            break;
        case 'mistral':
            result = await callOpenAICompatible(provider.endpoint, apiKey, modelId, request);
            break;
        case 'cohere':
            result = await callCohere(apiKey, modelId, request);
            break;
        default:
            throw new Error(`Provider ${providerId} not implemented`);
    }

    const callLatency = Date.now() - callStartTime;
    await log({ level: 'DEBUG', source: 'ai-router', message: `Provider ${providerId} call completed`, traceId, duration: callLatency, details: { model: modelId, tokens: result.tokensUsed } });

    return result;
}

// Provider-specific implementations
async function callAnthropic(apiKey, model, request) {
    const response = await fetch('https://api.anthropic.com/v1/messages', {
        method: 'POST',
        headers: {
            'x-api-key': apiKey,
            'anthropic-version': '2023-06-01',
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
            model,
            max_tokens: request.maxTokens || 1024,
            system: request.system,
            messages: request.messages || [{ role: 'user', content: request.prompt }],
            ...(request.tools && { tools: request.tools })
        })
    });

    if (!response.ok) {
        const error = await response.text();
        throw new Error(`Anthropic API error: ${response.status} - ${error}`);
    }

    const data = await response.json();
    return {
        content: data.content?.[0]?.text || '',
        contentBlocks: data.content,
        stopReason: data.stop_reason,
        tokensUsed: (data.usage?.input_tokens || 0) + (data.usage?.output_tokens || 0),
        model
    };
}

async function callOpenAICompatible(endpoint, apiKey, model, request) {
    const response = await fetch(endpoint, {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
            model,
            messages: request.messages || [
                { role: 'system', content: request.system || '' },
                { role: 'user', content: request.prompt }
            ],
            max_tokens: request.maxTokens || 1024,
            temperature: request.temperature || 0.7
        })
    });

    if (!response.ok) {
        const error = await response.text();
        throw new Error(`API error: ${response.status} - ${error}`);
    }

    const data = await response.json();
    return {
        content: data.choices?.[0]?.message?.content || '',
        tokensUsed: (data.usage?.prompt_tokens || 0) + (data.usage?.completion_tokens || 0),
        model
    };
}

async function callGemini(apiKey, model, request) {
    const endpoint = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`;

    const response = await fetch(endpoint, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
            contents: [{
                parts: [{ text: request.prompt }]
            }],
            generationConfig: {
                maxOutputTokens: request.maxTokens || 1024
            }
        })
    });

    if (!response.ok) {
        const error = await response.text();
        throw new Error(`Gemini API error: ${response.status} - ${error}`);
    }

    const data = await response.json();
    return {
        content: data.candidates?.[0]?.content?.parts?.[0]?.text || '',
        tokensUsed: data.usageMetadata?.totalTokenCount || 0,
        model
    };
}

async function callCohere(apiKey, model, request) {
    const response = await fetch('https://api.cohere.ai/v1/chat', {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
            model,
            message: request.prompt,
            preamble: request.system
        })
    });

    if (!response.ok) {
        const error = await response.text();
        throw new Error(`Cohere API error: ${response.status} - ${error}`);
    }

    const data = await response.json();
    return {
        content: data.text || '',
        tokensUsed: (data.meta?.tokens?.input_tokens || 0) + (data.meta?.tokens?.output_tokens || 0),
        model
    };
}

// ============================================
// LOGGING
// ============================================

async function logUsage(functionId, provider, model, latencyMs, tokensUsed, error, usedFallback, isOptimized = false, savings = 0) {
    try {
        await dataAccess.insertRecord(COLLECTION_KEYS.usageLog, {
            functionId, provider, model, latencyMs, tokensUsed: tokensUsed || 0,
            error: error || null, usedFallback, isOptimized, savings, timestamp: new Date()
        }, { suppressAuth: true });
    } catch (e) {
        console.error('Failed to log AI usage:', e);
    }
}

async function logAuditEntry(action, targetId, details) {
    try {
        const member = await currentMember.getMember();
        const auditRecord = {
            action, targetType: 'ai_router', targetId, details,
            adminId: member?._id || 'system', adminEmail: member?.loginEmail || 'system',
            timestamp: new Date()
        };
        await dataAccess.insertRecord(COLLECTION_KEYS.auditLog, auditRecord, { suppressAuth: true });
    } catch (e) {
        console.error('Failed to log audit entry:', e);
    }
}

// ============================================
// HEALTH CHECK
// ============================================

/**
 * Test connectivity to a specific provider
 */
export async function testProvider(providerId) {
    await requireAdmin();

    const provider = PROVIDER_REGISTRY[providerId];
    if (!provider) {
        throw new Error(`Unknown provider: ${providerId}`);
    }

    try {
        const apiKey = await getSecret(provider.secretKey);
        if (!apiKey) {
            return {
                provider: providerId,
                status: 'not_configured',
                message: `API key not set. Add secret: ${provider.secretKey}`
            };
        }

        // Simple test request
        const startTime = Date.now();
        const response = await callProvider(providerId, provider.models[0].id, {
            prompt: 'Say "OK" and nothing else.',
            maxTokens: 10
        });

        return {
            provider: providerId,
            status: 'healthy',
            latencyMs: Date.now() - startTime,
            model: provider.models[0].id,
            response: response.content.substring(0, 50)
        };

    } catch (error) {
        return {
            provider: providerId,
            status: 'error',
            message: error.message
        };
    }
}

/**
 * Test all configured providers
 */
export async function testAllProviders() {
    await requireAdmin();

    const results = {};
    for (const providerId of Object.keys(PROVIDER_REGISTRY)) {
        results[providerId] = await testProvider(providerId);
    }
    return results;
}



// ============================================
// COST OPTIMIZER CONFIGURATION (Phase 1)
// ============================================

/**
 * Get current cost optimizer configuration
 */
export async function getCostOptimizerConfig() {
    await requireAdmin();

    try {
        // Singleton pattern - always ID 'global'
        const result = await dataAccess.queryRecords(COLLECTION_KEYS.optimizerConfig, {
            filters: { configId: 'global' },
            limit: 1,
            suppressAuth: true
        });

        if (result.items && result.items.length > 0) {
            return result.items[0];
        }

        // Return default if not initialized
        return {
            configId: 'global',
            enabled: false,
            qualityThreshold: 0.80,
            maxCostPerRequest: 0.10,
            preferredProviders: [],
            excludedProviders: []
        };
    } catch (error) {
        console.error('Error fetching cost optimizer config:', error);
        throw new Error('Failed to fetch cost optimizer config');
    }
}

/**
 * Update cost optimizer configuration
 */
export async function updateCostOptimizerConfig(config) {
    await requireAdmin();

    try {
        // Check if exists
        const existing = await getCostOptimizerConfig();
        const member = await currentMember.getMember();

        const configData = {
            ...existing,
            ...config,
            configId: 'global', // Enforce singleton
            updatedAt: new Date(),
            updatedBy: member?.loginEmail || 'admin'
        };

        let result;
        if (existing._id) {
            result = await dataAccess.updateRecord(COLLECTION_KEYS.optimizerConfig, configData, { suppressAuth: true });
        } else {
            result = await dataAccess.insertRecord(COLLECTION_KEYS.optimizerConfig, configData, { suppressAuth: true });
        }

        await logAuditEntry('updateCostOptimizerConfig', 'global', {
            enabled: config.enabled,
            qualityThreshold: config.qualityThreshold
        });

        return { success: true, config: result };

    } catch (error) {
        console.error('Error updating cost optimizer config:', error);
        throw new Error('Failed to update cost optimizer config');
    }
}

// ============================================
// PROVIDER COST METRICS
// ============================================

/**
 * Get all provider cost and quality metrics
 */
export async function getProviderCostMetrics() {
    await requireAdmin();

    try {
        if (
            providerCostMetricsCache &&
            (Date.now() - providerCostMetricsCacheTime) < CONFIG.providerCostMetricsCacheExpiry
        ) {
            return providerCostMetricsCache;
        }

        const result = await dataAccess.queryRecords(COLLECTION_KEYS.providerCosts, {
            limit: 100, // Should cover all models
            sort: [{ field: 'providerId', direction: 'asc' }],
            suppressAuth: true
        });

        providerCostMetricsCache = result.items || [];
        providerCostMetricsCacheTime = Date.now();
        return providerCostMetricsCache;
    } catch (error) {
        console.error('Error fetching provider cost metrics:', error);
        throw new Error('Failed to fetch provider cost metrics');
    }
}

/**
 * Update cost data for a specific provider/model
 * Used by scheduled jobs or manual overrides
 */
export async function updateProviderCostData(providerId, costData) {
    await requireAdmin(); // Or system auth

    try {
        // Find existing record
        const existingResult = await dataAccess.queryRecords(COLLECTION_KEYS.providerCosts, {
            filters: { providerId, modelId: costData.modelId },
            limit: 1,
            suppressAuth: true
        });

        let record = {};
        if (existingResult.items && existingResult.items.length > 0) {
            record = existingResult.items[0];
        }

        // Update fields
        record.providerId = providerId;
        record.modelId = costData.modelId;
        if (costData.costInput !== undefined) record.costInput = costData.costInput;
        if (costData.costOutput !== undefined) record.costOutput = costData.costOutput;
        if (costData.qualityScore !== undefined) record.qualityScore = costData.qualityScore;
        if (costData.avgLatencyMs !== undefined) record.avgLatencyMs = costData.avgLatencyMs;
        if (costData.availabilityRate !== undefined) record.availabilityRate = costData.availabilityRate;
        if (costData.isActive !== undefined) record.isActive = costData.isActive;
        record.lastUpdated = new Date();

        let result;
        if (record._id) {
            result = await dataAccess.updateRecord(COLLECTION_KEYS.providerCosts, record, { suppressAuth: true });
        } else {
            result = await dataAccess.insertRecord(COLLECTION_KEYS.providerCosts, record, { suppressAuth: true });
        }
        providerCostMetricsCache = null;
        providerCostMetricsCacheTime = 0;

        return { success: true, data: result };

    } catch (error) {
        console.error('Error updating provider cost data:', error);
        throw new Error('Failed to update provider cost data');
    }
}

/**
 * Helper to calculate quality score based on metrics
 */
export function calculateQualityScore(successRate, latencyMs) {
    // Baseline is 1.0
    // Success rate penalty: direct proportional
    // Latency penalty: -0.1 for every 2s above 1s

    let score = 1.0;

    if (successRate < 1.0) {
        score -= (1.0 - successRate);
    }

    if (latencyMs > 1000) {
        const latencyPenalty = Math.min(0.3, (latencyMs - 1000) / 20000); // Gentle slope
        score -= latencyPenalty;
    }

    return Math.max(0.1, Math.min(1.0, score));
}

// ============================================
// SAVINGS REPORTING & JOBS (Phase 1)
// ============================================

/**
 * Generate cost savings report for a period
 */
export async function getCostSavingsReport(period = 'month') {
    await requireAdmin();

    const endDate = new Date();
    let startDate = new Date();
    if (period === 'week') startDate.setDate(endDate.getDate() - 7);
    else if (period === 'month') startDate.setDate(endDate.getDate() - 30);
    else if (period === 'day') startDate.setDate(endDate.getDate() - 1);

    try {
        // Query logs
        const logs = await dataAccess.queryRecords(COLLECTION_KEYS.usageLog, {
            filters: { timestamp: { gte: startDate } },
            limit: 1000,
            suppressAuth: true
        });

        let totalRequests = 0;
        let optimizedRequests = 0;
        let totalSavings = 0;
        let totalCost = 0;

        for (const log of (logs.items || [])) {
            totalRequests++;
            if (log.isOptimized) {
                optimizedRequests++;
                // Savings is stored as 'savingsEstimate' per 1k tokens? 
                // In routeAIRequest: savingsEstimate = cost - optimalCost (per 1k)
                // logUsage called with savingsEstimate.
                // Actual savings = (tokens / 1000) * savingsEstimate.

                // If log.savings is unit savings:
                // cost = (log.tokensUsed / 1000) * unitCost

                const unitSavings = log.savings || 0;
                const actualSavings = (log.tokensUsed / 1000) * unitSavings;
                totalSavings += actualSavings;
            }

            // Estimate total cost (approx)
            // Ideally we'd store actual cost in log too.
            const unitCost = await estimateRequestCost(log.provider, log.model);
            totalCost += (log.tokensUsed / 1000) * unitCost;
        }

        return {
            period,
            totalRequests,
            optimizedRequests,
            totalCost: parseFloat(totalCost.toFixed(4)),
            totalSavings: parseFloat(totalSavings.toFixed(4)),
            savingsRate: totalRequests > 0 ? (optimizedRequests / totalRequests) : 0,
            avgSavingsPerRequest: optimizedRequests > 0 ? (totalSavings / optimizedRequests) : 0
        };

    } catch (error) {
        console.error('Error generating savings report:', error);
        return { period, error: error.message, totalSavings: 0 };
    }
}

/**
 * Scheduler Job: Update Provider Costs
 * Runs hourly to refresh quality scores or fetch external prices if available
 */
export async function updateProviderCostsJob() {
    console.log('[JOB] Starting updateProviderCostsJob...');
    try {
        // 1. Fetch current metrics
        const metrics = await getProviderCostMetrics();

        // 2. Recalculate quality scores based on recent usage
        // Query recent usage for each provider
        const startDate = new Date();
        startDate.setHours(startDate.getHours() - 24); // Last 24h

        for (const metric of metrics) {
            const usage = await dataAccess.queryRecords(COLLECTION_KEYS.usageLog, {
                filters: {
                    provider: metric.providerId,
                    model: metric.modelId,
                    timestamp: { gte: startDate }
                },
                limit: 100, // Sample
                suppressAuth: true
            });

            if (usage.items && usage.items.length > 0) {
                const items = usage.items;
                const successCount = items.filter(i => !i.error).length;
                const successRate = successCount / items.length;
                const avgLatency = items.reduce((acc, i) => acc + (i.latencyMs || 0), 0) / items.length;

                // Update metric
                const qualityScore = calculateQualityScore(successRate, avgLatency);

                await updateProviderCostData(metric.providerId, {
                    modelId: metric.modelId,
                    qualityScore: parseFloat(qualityScore.toFixed(2)),
                    avgLatencyMs: Math.round(avgLatency),
                    availabilityRate: parseFloat(successRate.toFixed(2))
                });
            }
        }

        return { success: true };
    } catch (error) {
        console.error('[JOB] updateProviderCostsJob failed:', error);
        return { success: false, error: error.message };
    }
}
