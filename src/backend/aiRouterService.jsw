/**
 * AI Router Service - LLM-Agnostic Provider Management
 *
 * This service enables administrators to configure which AI provider
 * handles each function in the system. Supports hot-swapping providers
 * based on speed, quality, cost, or specific use case requirements.
 *
 * Current Integrations:
 * - Claude (Anthropic) - Synthesis, reasoning, safety-focused responses
 * - Perplexity - Web research, real-time information
 * - Gemini (Google) - OCR, multimodal processing
 * - OpenAI - General purpose, embeddings
 * - Groq - Ultra-fast inference for real-time needs
 * - Mistral - European alternative, good for certain tasks
 */

import { getSecret } from 'wix-secrets-backend';
import { fetch } from 'wix-fetch';
import { currentMember } from 'wix-members-backend';
import { log, logAIOperation, startTrace, endTrace } from 'backend/observabilityService';
import * as dataAccess from 'backend/dataAccess';

// ============================================
// CONFIGURATION & CONSTANTS
// ============================================

const CONFIG = {
    cacheExpiry: 5 * 60 * 1000 // 5 minutes cache for config
};

// Collection keys for dataAccess routing
const COLLECTION_KEYS = {
    routerConfig: 'aiRouterConfig',
    usageLog: 'aiUsageLog',
    auditLog: 'auditLog'
};

// In-memory cache for router config
let configCache = null;
let configCacheTime = 0;

// ============================================
// PROVIDER REGISTRY
// ============================================

/**
 * Complete registry of all supported AI providers
 * Each provider has models, endpoints, capabilities, and characteristics
 */
const PROVIDER_REGISTRY = {
    anthropic: {
        name: 'Anthropic (Claude)',
        description: 'Advanced reasoning, safety-focused, excellent for synthesis',
        secretKey: 'CLAUDE_API_KEY',
        endpoint: 'https://api.anthropic.com/v1/messages',
        models: [
            { id: 'claude-sonnet-4-20250514', name: 'Claude Sonnet 4', tier: 'standard', speed: 'medium', quality: 'high' },
            { id: 'claude-3-5-sonnet-20241022', name: 'Claude 3.5 Sonnet', tier: 'standard', speed: 'medium', quality: 'high' },
            { id: 'claude-3-haiku-20240307', name: 'Claude 3 Haiku', tier: 'fast', speed: 'fast', quality: 'good' },
            { id: 'claude-3-opus-20240229', name: 'Claude 3 Opus', tier: 'premium', speed: 'slow', quality: 'highest' }
        ],
        capabilities: ['synthesis', 'reasoning', 'analysis', 'chat', 'code', 'safety'],
        characteristics: {
            latency: 'medium',
            costTier: 'premium',
            contextWindow: 200000,
            strengths: ['Complex reasoning', 'Safety', 'Following instructions', 'Long context']
        }
    },

    openai: {
        name: 'OpenAI',
        description: 'Industry standard, broad capabilities, strong ecosystem',
        secretKey: 'OPENAI_API_KEY',
        endpoint: 'https://api.openai.com/v1/chat/completions',
        models: [
            { id: 'gpt-4o', name: 'GPT-4o', tier: 'standard', speed: 'medium', quality: 'high' },
            { id: 'gpt-4o-mini', name: 'GPT-4o Mini', tier: 'fast', speed: 'fast', quality: 'good' },
            { id: 'gpt-4-turbo', name: 'GPT-4 Turbo', tier: 'premium', speed: 'medium', quality: 'high' },
            { id: 'gpt-3.5-turbo', name: 'GPT-3.5 Turbo', tier: 'economy', speed: 'fast', quality: 'standard' }
        ],
        capabilities: ['synthesis', 'reasoning', 'chat', 'code', 'embeddings', 'vision'],
        characteristics: {
            latency: 'medium',
            costTier: 'standard',
            contextWindow: 128000,
            strengths: ['General purpose', 'Code generation', 'Ecosystem integration']
        }
    },

    groq: {
        name: 'Groq',
        description: 'Ultra-fast inference, ideal for real-time applications',
        secretKey: 'GROQ_API_KEY',
        endpoint: 'https://api.groq.com/openai/v1/chat/completions',
        models: [
            { id: 'llama-3.3-70b-versatile', name: 'Llama 3.3 70B', tier: 'standard', speed: 'ultra-fast', quality: 'high' },
            { id: 'llama-3.1-8b-instant', name: 'Llama 3.1 8B Instant', tier: 'fast', speed: 'ultra-fast', quality: 'good' },
            { id: 'mixtral-8x7b-32768', name: 'Mixtral 8x7B', tier: 'standard', speed: 'ultra-fast', quality: 'high' },
            { id: 'gemma2-9b-it', name: 'Gemma 2 9B', tier: 'fast', speed: 'ultra-fast', quality: 'good' }
        ],
        capabilities: ['chat', 'reasoning', 'analysis', 'real-time'],
        characteristics: {
            latency: 'ultra-low',
            costTier: 'economy',
            contextWindow: 32768,
            strengths: ['Speed', 'Real-time responses', 'Cost efficiency']
        }
    },

    perplexity: {
        name: 'Perplexity',
        description: 'Web-connected research, real-time information retrieval',
        secretKey: 'PERPLEXITY_API_KEY',
        endpoint: 'https://api.perplexity.ai/chat/completions',
        models: [
            { id: 'sonar-pro', name: 'Sonar Pro', tier: 'premium', speed: 'medium', quality: 'high' },
            { id: 'sonar', name: 'Sonar', tier: 'standard', speed: 'fast', quality: 'good' },
            { id: 'sonar-reasoning', name: 'Sonar Reasoning', tier: 'premium', speed: 'slow', quality: 'highest' }
        ],
        capabilities: ['research', 'web-search', 'real-time-info', 'citations'],
        characteristics: {
            latency: 'medium',
            costTier: 'standard',
            contextWindow: 128000,
            strengths: ['Real-time web access', 'Citations', 'Current information']
        }
    },

    google: {
        name: 'Google (Gemini)',
        description: 'Multimodal excellence, strong at OCR and vision tasks',
        secretKey: 'GEMINI_API_KEY',
        endpoint: 'https://generativelanguage.googleapis.com/v1beta/models',
        models: [
            { id: 'gemini-1.5-flash', name: 'Gemini 1.5 Flash', tier: 'fast', speed: 'fast', quality: 'good' },
            { id: 'gemini-1.5-pro', name: 'Gemini 1.5 Pro', tier: 'premium', speed: 'medium', quality: 'high' },
            { id: 'gemini-2.0-flash-exp', name: 'Gemini 2.0 Flash', tier: 'standard', speed: 'fast', quality: 'high' }
        ],
        capabilities: ['ocr', 'vision', 'multimodal', 'reasoning', 'code'],
        characteristics: {
            latency: 'low',
            costTier: 'economy',
            contextWindow: 1000000,
            strengths: ['OCR', 'Vision', 'Long context', 'Multimodal']
        }
    },

    mistral: {
        name: 'Mistral AI',
        description: 'European provider, strong multilingual and code capabilities',
        secretKey: 'MISTRAL_API_KEY',
        endpoint: 'https://api.mistral.ai/v1/chat/completions',
        models: [
            { id: 'mistral-large-latest', name: 'Mistral Large', tier: 'premium', speed: 'medium', quality: 'high' },
            { id: 'mistral-medium-latest', name: 'Mistral Medium', tier: 'standard', speed: 'fast', quality: 'good' },
            { id: 'mistral-small-latest', name: 'Mistral Small', tier: 'economy', speed: 'fast', quality: 'standard' },
            { id: 'codestral-latest', name: 'Codestral', tier: 'standard', speed: 'fast', quality: 'high' }
        ],
        capabilities: ['chat', 'code', 'reasoning', 'multilingual'],
        characteristics: {
            latency: 'low',
            costTier: 'standard',
            contextWindow: 32000,
            strengths: ['Code', 'Multilingual', 'European data residency']
        }
    },

    cohere: {
        name: 'Cohere',
        description: 'Enterprise-focused, excellent embeddings and RAG',
        secretKey: 'COHERE_API_KEY',
        endpoint: 'https://api.cohere.ai/v1/chat',
        models: [
            { id: 'command-r-plus', name: 'Command R+', tier: 'premium', speed: 'medium', quality: 'high' },
            { id: 'command-r', name: 'Command R', tier: 'standard', speed: 'fast', quality: 'good' },
            { id: 'command-light', name: 'Command Light', tier: 'economy', speed: 'fast', quality: 'standard' }
        ],
        capabilities: ['chat', 'rag', 'embeddings', 'rerank', 'enterprise'],
        characteristics: {
            latency: 'medium',
            costTier: 'standard',
            contextWindow: 128000,
            strengths: ['RAG', 'Embeddings', 'Enterprise features', 'Reranking']
        }
    }
};

// ============================================
// FUNCTION CATEGORIES
// ============================================

/**
 * All AI functions in the system that can be routed
 */
const FUNCTION_REGISTRY = {
    // Core Enrichment
    carrier_synthesis: {
        name: 'Carrier Data Synthesis',
        description: 'Synthesizes carrier information into structured enrichment data',
        currentProvider: 'anthropic',
        currentModel: 'claude-sonnet-4-20250514',
        recommendedProviders: ['anthropic', 'openai'],
        requirements: ['synthesis', 'reasoning'],
        priority: 'quality',
        category: 'enrichment'
    },

    web_research: {
        name: 'Web Research',
        description: 'Fetches real-time information about carriers from the web',
        currentProvider: 'perplexity',
        currentModel: 'sonar-pro',
        recommendedProviders: ['perplexity'],
        requirements: ['research', 'web-search'],
        priority: 'accuracy',
        category: 'research'
    },

    social_scanning: {
        name: 'Social Media Scanning',
        description: 'Scans Reddit, forums, and social media for driver sentiment',
        currentProvider: 'perplexity',
        currentModel: 'sonar-pro',
        recommendedProviders: ['perplexity'],
        requirements: ['research', 'real-time-info'],
        priority: 'depth',
        category: 'research'
    },

    // Document Processing
    document_ocr: {
        name: 'Document OCR',
        description: 'Extracts text and data from CDL, med cards, and other documents',
        currentProvider: 'google',
        currentModel: 'gemini-1.5-flash',
        recommendedProviders: ['google', 'openai'],
        requirements: ['ocr', 'vision'],
        priority: 'accuracy',
        category: 'documents'
    },

    // Real-time Functions
    quick_classification: {
        name: 'Quick Classification',
        description: 'Fast classification of driver queries or document types',
        currentProvider: 'groq',
        currentModel: 'llama-3.3-70b-versatile',
        recommendedProviders: ['groq', 'anthropic'],
        requirements: ['chat'],
        priority: 'speed',
        category: 'real-time'
    },

    sentiment_analysis: {
        name: 'Sentiment Analysis',
        description: 'Analyzes driver reviews and feedback sentiment',
        currentProvider: 'groq',
        currentModel: 'llama-3.3-70b-versatile',
        recommendedProviders: ['groq', 'anthropic', 'openai'],
        requirements: ['analysis'],
        priority: 'speed',
        category: 'analysis'
    },

    // Chat & Support
    driver_chat: {
        name: 'Driver Chat Assistant',
        description: 'Handles driver questions and support conversations',
        currentProvider: 'anthropic',
        currentModel: 'claude-3-haiku-20240307',
        recommendedProviders: ['anthropic', 'openai', 'groq'],
        requirements: ['chat', 'safety'],
        priority: 'balanced',
        category: 'chat'
    },

    admin_assistant: {
        name: 'Admin Assistant',
        description: 'Helps administrators with queries and data analysis',
        currentProvider: 'anthropic',
        currentModel: 'claude-sonnet-4-20250514',
        recommendedProviders: ['anthropic', 'openai'],
        requirements: ['reasoning', 'analysis'],
        priority: 'quality',
        category: 'chat'
    },

    // Data Processing
    data_extraction: {
        name: 'Data Extraction',
        description: 'Extracts structured data from unstructured text',
        currentProvider: 'anthropic',
        currentModel: 'claude-3-haiku-20240307',
        recommendedProviders: ['anthropic', 'openai', 'mistral'],
        requirements: ['reasoning'],
        priority: 'accuracy',
        category: 'processing'
    },

    translation: {
        name: 'Translation',
        description: 'Translates content for multilingual support',
        currentProvider: 'mistral',
        currentModel: 'mistral-large-latest',
        recommendedProviders: ['mistral', 'openai', 'google'],
        requirements: ['multilingual'],
        priority: 'quality',
        category: 'processing'
    },

    // Embeddings & Search
    embeddings: {
        name: 'Text Embeddings',
        description: 'Generates embeddings for semantic search',
        currentProvider: 'openai',
        currentModel: 'text-embedding-3-small',
        recommendedProviders: ['openai', 'cohere'],
        requirements: ['embeddings'],
        priority: 'quality',
        category: 'search'
    }
};

// ============================================
// AUTHORIZATION
// ============================================

async function isAdmin() {
    try {
        const member = await currentMember.getMember({ fieldsets: ['FULL'] });
        if (!member) return false;

        const adminRoles = ['admin', 'super_admin', 'ops_admin'];
        const memberRole = member.contactDetails?.customFields?.role || '';

        return adminRoles.includes(memberRole.toLowerCase());
    } catch (error) {
        console.error('Admin check failed:', error);
        return false;
    }
}

async function requireAdmin() {
    const authorized = await isAdmin();
    if (!authorized) {
        throw new Error('Unauthorized: Admin access required');
    }
}

async function isSuperAdmin() {
    try {
        const member = await currentMember.getMember({ fieldsets: ['FULL'] });
        if (!member) return false;

        const memberRole = member.contactDetails?.customFields?.role || '';
        return memberRole.toLowerCase() === 'super_admin';
    } catch (error) {
        return false;
    }
}

// ============================================
// ROUTER CONFIGURATION
// ============================================

/**
 * Get current router configuration
 * Returns cached config if fresh, otherwise fetches from database
 */
export async function getRouterConfig() {
    await requireAdmin();

    // Check cache
    if (configCache && (Date.now() - configCacheTime) < CONFIG.cacheExpiry) {
        return configCache;
    }

    try {
        const result = await dataAccess.queryRecords(COLLECTION_KEYS.routerConfig, {
            limit: 100,
            suppressAuth: true
        });

        // Build config map
        const configMap = {};
        for (const item of (result.items || [])) {
            configMap[item.functionId] = {
                provider: item.provider,
                model: item.model,
                enabled: item.enabled !== false,
                fallbackProvider: item.fallbackProvider,
                fallbackModel: item.fallbackModel,
                customSettings: item.customSettings || {},
                lastModified: item._updatedDate
            };
        }

        // Merge with defaults from FUNCTION_REGISTRY
        const fullConfig = {};
        for (const [funcId, funcDef] of Object.entries(FUNCTION_REGISTRY)) {
            fullConfig[funcId] = {
                ...funcDef,
                provider: configMap[funcId]?.provider || funcDef.currentProvider,
                model: configMap[funcId]?.model || funcDef.currentModel,
                enabled: configMap[funcId]?.enabled !== false,
                fallbackProvider: configMap[funcId]?.fallbackProvider || null,
                fallbackModel: configMap[funcId]?.fallbackModel || null,
                customSettings: configMap[funcId]?.customSettings || {},
                isCustomized: !!configMap[funcId]
            };
        }

        // Update cache
        configCache = fullConfig;
        configCacheTime = Date.now();

        return fullConfig;

    } catch (error) {
        console.error('Error fetching router config:', error);
        // Return defaults
        return FUNCTION_REGISTRY;
    }
}

/**
 * Update configuration for a specific function
 */
export async function updateFunctionConfig(functionId, config) {
    await requireAdmin();

    if (!FUNCTION_REGISTRY[functionId]) {
        throw new Error(`Unknown function: ${functionId}`);
    }

    // Validate provider and model
    const provider = PROVIDER_REGISTRY[config.provider];
    if (!provider) {
        throw new Error(`Unknown provider: ${config.provider}`);
    }

    const validModel = provider.models.find(m => m.id === config.model);
    if (!validModel) {
        throw new Error(`Invalid model ${config.model} for provider ${config.provider}`);
    }

    try {
        // Check if config exists
        const existingResult = await dataAccess.queryRecords(COLLECTION_KEYS.routerConfig, {
            filters: { functionId: functionId },
            limit: 1,
            suppressAuth: true
        });

        const member = await currentMember.getMember();
        const configData = {
            functionId,
            provider: config.provider,
            model: config.model,
            enabled: config.enabled !== false,
            fallbackProvider: config.fallbackProvider || null,
            fallbackModel: config.fallbackModel || null,
            customSettings: config.customSettings || {},
            modifiedBy: member?.loginEmail || 'admin',
            modifiedAt: new Date()
        };

        if (existingResult.success && existingResult.items.length > 0) {
            configData._id = existingResult.items[0]._id;
            await dataAccess.updateRecord(COLLECTION_KEYS.routerConfig, configData, { suppressAuth: true });
        } else {
            await dataAccess.insertRecord(COLLECTION_KEYS.routerConfig, configData, { suppressAuth: true });
        }

        // Clear cache
        configCache = null;

        // Log to audit
        await logAuditEntry('updateAIRouterConfig', functionId, {
            provider: config.provider,
            model: config.model
        });

        return { success: true, functionId, config: configData };

    } catch (error) {
        console.error('Error updating function config:', error);
        throw new Error('Failed to update configuration');
    }
}

/**
 * Reset function to default configuration
 */
export async function resetFunctionConfig(functionId) {
    await requireAdmin();

    if (!FUNCTION_REGISTRY[functionId]) {
        throw new Error(`Unknown function: ${functionId}`);
    }

    try {
        const existingResult = await dataAccess.queryRecords(COLLECTION_KEYS.routerConfig, {
            filters: { functionId: functionId },
            limit: 1,
            suppressAuth: true
        });

        if (existingResult.success && existingResult.items.length > 0) {
            await dataAccess.removeRecord(COLLECTION_KEYS.routerConfig, existingResult.items[0]._id, { suppressAuth: true });
        }

        // Clear cache
        configCache = null;

        await logAuditEntry('resetAIRouterConfig', functionId, {
            resetTo: 'default'
        });

        return { success: true, functionId, resetToDefault: true };

    } catch (error) {
        console.error('Error resetting function config:', error);
        throw new Error('Failed to reset configuration');
    }
}

// ============================================
// PROVIDER INFORMATION
// ============================================

/**
 * Get all available providers with their capabilities
 */
export async function getProviders() {
    await requireAdmin();

    // Check which providers have API keys configured
    const providerStatus = {};

    for (const [providerId, provider] of Object.entries(PROVIDER_REGISTRY)) {
        let hasApiKey = false;
        try {
            const key = await getSecret(provider.secretKey);
            hasApiKey = !!key;
        } catch (e) {
            hasApiKey = false;
        }

        providerStatus[providerId] = {
            ...provider,
            id: providerId,
            configured: hasApiKey,
            apiKeySecret: provider.secretKey // So admin knows which secret to set
        };
    }

    return providerStatus;
}

/**
 * Get all function definitions
 */
export async function getFunctions() {
    await requireAdmin();

    return Object.entries(FUNCTION_REGISTRY).map(([id, func]) => ({
        id,
        ...func
    }));
}

/**
 * Get models for a specific provider
 */
export async function getProviderModels(providerId) {
    await requireAdmin();

    const provider = PROVIDER_REGISTRY[providerId];
    if (!provider) {
        throw new Error(`Unknown provider: ${providerId}`);
    }

    return provider.models;
}

// ============================================
// USAGE STATISTICS
// ============================================

/**
 * Get AI usage statistics
 */
export async function getUsageStats(period = 'week') {
    await requireAdmin();

    try {
        const now = new Date();
        const startDate = period === 'month'
            ? new Date(now.getTime() - 30 * 24 * 60 * 60 * 1000)
            : new Date(now.getTime() - 7 * 24 * 60 * 60 * 1000);

        const result = await dataAccess.queryRecords(COLLECTION_KEYS.usageLog, {
            filters: { timestamp: { gte: startDate } },
            limit: 1000,
            suppressAuth: true
        });

        // Aggregate by function and provider
        const byFunction = {};
        const byProvider = {};
        let totalCalls = 0;
        let totalTokens = 0;
        let totalLatency = 0;
        let errorCount = 0;

        for (const logItem of (result.items || [])) {
            totalCalls++;
            totalTokens += logItem.tokensUsed || 0;
            totalLatency += logItem.latencyMs || 0;
            if (logItem.error) errorCount++;

            // By function
            if (!byFunction[logItem.functionId]) {
                byFunction[logItem.functionId] = { calls: 0, tokens: 0, errors: 0 };
            }
            byFunction[logItem.functionId].calls++;
            byFunction[logItem.functionId].tokens += logItem.tokensUsed || 0;
            if (logItem.error) byFunction[logItem.functionId].errors++;

            // By provider
            if (!byProvider[logItem.provider]) {
                byProvider[logItem.provider] = { calls: 0, tokens: 0, avgLatency: 0, errors: 0 };
            }
            byProvider[logItem.provider].calls++;
            byProvider[logItem.provider].tokens += logItem.tokensUsed || 0;
            if (logItem.error) byProvider[logItem.provider].errors++;
        }

        // Calculate averages
        for (const provider of Object.values(byProvider)) {
            provider.avgLatency = provider.calls > 0 ? Math.round(totalLatency / provider.calls) : 0;
        }

        return {
            period,
            totalCalls,
            totalTokens,
            avgLatency: totalCalls > 0 ? Math.round(totalLatency / totalCalls) : 0,
            errorRate: totalCalls > 0 ? Math.round((errorCount / totalCalls) * 100) : 0,
            byFunction,
            byProvider
        };

    } catch (error) {
        console.error('Error fetching usage stats:', error);
        return { period, totalCalls: 0, byFunction: {}, byProvider: {} };
    }
}

// ============================================
// CORE ROUTER FUNCTION
// ============================================

/**
 * Route an AI request to the configured provider
 * This is the main function other services will call
 */
export async function routeAIRequest(functionId, request, traceId = null) {
    const startTime = Date.now();

    // Start trace if not provided
    let localTraceId = traceId;
    let traceCreated = false;
    if (!localTraceId) {
        const trace = await startTrace('routeAIRequest', { functionId, tags: ['ai-router'] });
        localTraceId = trace.traceId;
        traceCreated = true;
    }

    await log({ level: 'INFO', source: 'ai-router', message: `Routing AI request: ${functionId}`, traceId: localTraceId });

    if (!FUNCTION_REGISTRY[functionId]) {
        await log({ level: 'ERROR', source: 'ai-router', message: `Unknown function: ${functionId}`, traceId: localTraceId });
        throw new Error(`Unknown function: ${functionId}`);
    }

    // Get current configuration
    let config;
    try {
        const fullConfig = await getRouterConfigInternal();
        config = fullConfig[functionId] || FUNCTION_REGISTRY[functionId];
    } catch (e) {
        config = FUNCTION_REGISTRY[functionId];
    }

    if (!config.enabled) {
        await log({ level: 'WARN', source: 'ai-router', message: `Function ${functionId} is disabled`, traceId: localTraceId });
        throw new Error(`Function ${functionId} is disabled`);
    }

    const provider = PROVIDER_REGISTRY[config.provider];
    if (!provider) {
        throw new Error(`Provider ${config.provider} not found`);
    }

    let response;
    let error = null;
    let usedFallback = false;

    try {
        response = await callProvider(config.provider, config.model, request, localTraceId);
    } catch (primaryError) {
        console.error(`Primary provider ${config.provider} failed:`, primaryError.message);
        await log({ level: 'WARN', source: 'ai-router', message: `Primary provider ${config.provider} failed`, traceId: localTraceId, details: { error: primaryError.message } });

        // Try fallback if configured
        if (config.fallbackProvider && config.fallbackModel) {
            try {
                console.log(`Attempting fallback to ${config.fallbackProvider}...`);
                await log({ level: 'INFO', source: 'ai-router', message: `Attempting fallback to ${config.fallbackProvider}`, traceId: localTraceId });
                response = await callProvider(config.fallbackProvider, config.fallbackModel, request, localTraceId);
                usedFallback = true;
            } catch (fallbackError) {
                error = fallbackError.message;
                await log({ level: 'ERROR', source: 'ai-router', message: `All providers failed for ${functionId}`, traceId: localTraceId, details: { primary: primaryError.message, fallback: fallbackError.message } });
                if (traceCreated) await endTrace(localTraceId, 'error', { error: 'All providers failed' });
                throw new Error(`All providers failed. Primary: ${primaryError.message}. Fallback: ${fallbackError.message}`);
            }
        } else {
            error = primaryError.message;
            if (traceCreated) await endTrace(localTraceId, 'error', { error: primaryError.message });
            throw primaryError;
        }
    }

    // Log usage
    const latency = Date.now() - startTime;
    await logUsage(functionId, config.provider, config.model, latency, response?.tokensUsed, error, usedFallback);

    // Log successful AI operation to observability
    await logAIOperation({
        source: 'ai-router',
        operation: 'route',
        functionId,
        provider: usedFallback ? config.fallbackProvider : config.provider,
        model: usedFallback ? config.fallbackModel : config.model,
        totalTokens: response?.tokensUsed,
        latencyMs: latency,
        usedFallback,
        traceId: localTraceId
    });

    if (traceCreated) await endTrace(localTraceId, 'completed', { provider: config.provider, latency, usedFallback });

    return response;
}

/**
 * Internal config getter (no auth check for internal use)
 */
async function getRouterConfigInternal() {
    if (configCache && (Date.now() - configCacheTime) < CONFIG.cacheExpiry) {
        return configCache;
    }

    try {
        const result = await dataAccess.queryRecords(COLLECTION_KEYS.routerConfig, {
            limit: 100,
            suppressAuth: true
        });

        const configMap = {};
        for (const item of (result.items || [])) {
            configMap[item.functionId] = {
                provider: item.provider,
                model: item.model,
                enabled: item.enabled !== false,
                fallbackProvider: item.fallbackProvider,
                fallbackModel: item.fallbackModel
            };
        }

        const fullConfig = {};
        for (const [funcId, funcDef] of Object.entries(FUNCTION_REGISTRY)) {
            fullConfig[funcId] = {
                ...funcDef,
                provider: configMap[funcId]?.provider || funcDef.currentProvider,
                model: configMap[funcId]?.model || funcDef.currentModel,
                enabled: configMap[funcId]?.enabled !== false,
                fallbackProvider: configMap[funcId]?.fallbackProvider,
                fallbackModel: configMap[funcId]?.fallbackModel
            };
        }

        configCache = fullConfig;
        configCacheTime = Date.now();

        return fullConfig;
    } catch (e) {
        return FUNCTION_REGISTRY;
    }
}

/**
 * Call a specific provider
 */
async function callProvider(providerId, modelId, request, traceId = null) {
    const provider = PROVIDER_REGISTRY[providerId];
    if (!provider) {
        throw new Error(`Unknown provider: ${providerId}`);
    }

    const apiKey = await getSecret(provider.secretKey);
    if (!apiKey) {
        throw new Error(`API key not configured for ${providerId}. Set secret: ${provider.secretKey}`);
    }

    const callStartTime = Date.now();
    let result;

    // Provider-specific request formatting
    switch (providerId) {
        case 'anthropic':
            result = await callAnthropic(apiKey, modelId, request);
            break;
        case 'openai':
        case 'groq':
            result = await callOpenAICompatible(provider.endpoint, apiKey, modelId, request);
            break;
        case 'perplexity':
            result = await callOpenAICompatible(provider.endpoint, apiKey, modelId, request);
            break;
        case 'google':
            result = await callGemini(apiKey, modelId, request);
            break;
        case 'mistral':
            result = await callOpenAICompatible(provider.endpoint, apiKey, modelId, request);
            break;
        case 'cohere':
            result = await callCohere(apiKey, modelId, request);
            break;
        default:
            throw new Error(`Provider ${providerId} not implemented`);
    }

    const callLatency = Date.now() - callStartTime;
    await log({ level: 'DEBUG', source: 'ai-router', message: `Provider ${providerId} call completed`, traceId, duration: callLatency, details: { model: modelId, tokens: result.tokensUsed } });

    return result;
}

// Provider-specific implementations
async function callAnthropic(apiKey, model, request) {
    const response = await fetch('https://api.anthropic.com/v1/messages', {
        method: 'POST',
        headers: {
            'x-api-key': apiKey,
            'anthropic-version': '2023-06-01',
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
            model,
            max_tokens: request.maxTokens || 1024,
            system: request.system,
            messages: request.messages || [{ role: 'user', content: request.prompt }]
        })
    });

    if (!response.ok) {
        const error = await response.text();
        throw new Error(`Anthropic API error: ${response.status} - ${error}`);
    }

    const data = await response.json();
    return {
        content: data.content?.[0]?.text || '',
        tokensUsed: (data.usage?.input_tokens || 0) + (data.usage?.output_tokens || 0),
        model
    };
}

async function callOpenAICompatible(endpoint, apiKey, model, request) {
    const response = await fetch(endpoint, {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
            model,
            messages: request.messages || [
                { role: 'system', content: request.system || '' },
                { role: 'user', content: request.prompt }
            ],
            max_tokens: request.maxTokens || 1024,
            temperature: request.temperature || 0.7
        })
    });

    if (!response.ok) {
        const error = await response.text();
        throw new Error(`API error: ${response.status} - ${error}`);
    }

    const data = await response.json();
    return {
        content: data.choices?.[0]?.message?.content || '',
        tokensUsed: (data.usage?.prompt_tokens || 0) + (data.usage?.completion_tokens || 0),
        model
    };
}

async function callGemini(apiKey, model, request) {
    const endpoint = `https://generativelanguage.googleapis.com/v1beta/models/${model}:generateContent?key=${apiKey}`;

    const response = await fetch(endpoint, {
        method: 'POST',
        headers: { 'Content-Type': 'application/json' },
        body: JSON.stringify({
            contents: [{
                parts: [{ text: request.prompt }]
            }],
            generationConfig: {
                maxOutputTokens: request.maxTokens || 1024
            }
        })
    });

    if (!response.ok) {
        const error = await response.text();
        throw new Error(`Gemini API error: ${response.status} - ${error}`);
    }

    const data = await response.json();
    return {
        content: data.candidates?.[0]?.content?.parts?.[0]?.text || '',
        tokensUsed: data.usageMetadata?.totalTokenCount || 0,
        model
    };
}

async function callCohere(apiKey, model, request) {
    const response = await fetch('https://api.cohere.ai/v1/chat', {
        method: 'POST',
        headers: {
            'Authorization': `Bearer ${apiKey}`,
            'Content-Type': 'application/json'
        },
        body: JSON.stringify({
            model,
            message: request.prompt,
            preamble: request.system
        })
    });

    if (!response.ok) {
        const error = await response.text();
        throw new Error(`Cohere API error: ${response.status} - ${error}`);
    }

    const data = await response.json();
    return {
        content: data.text || '',
        tokensUsed: (data.meta?.tokens?.input_tokens || 0) + (data.meta?.tokens?.output_tokens || 0),
        model
    };
}

// ============================================
// LOGGING
// ============================================

async function logUsage(functionId, provider, model, latencyMs, tokensUsed, error, usedFallback) {
    try {
        await dataAccess.insertRecord(COLLECTION_KEYS.usageLog, {
            functionId, provider, model, latencyMs, tokensUsed: tokensUsed || 0,
            error: error || null, usedFallback, timestamp: new Date()
        }, { suppressAuth: true });
    } catch (e) {
        console.error('Failed to log AI usage:', e);
    }
}

async function logAuditEntry(action, targetId, details) {
    try {
        const member = await currentMember.getMember();
        const auditRecord = {
            action, targetType: 'ai_router', targetId, details,
            adminId: member?._id || 'system', adminEmail: member?.loginEmail || 'system',
            timestamp: new Date()
        };
        await dataAccess.insertRecord(COLLECTION_KEYS.auditLog, auditRecord, { suppressAuth: true });
    } catch (e) {
        console.error('Failed to log audit entry:', e);
    }
}

// ============================================
// HEALTH CHECK
// ============================================

/**
 * Test connectivity to a specific provider
 */
export async function testProvider(providerId) {
    await requireAdmin();

    const provider = PROVIDER_REGISTRY[providerId];
    if (!provider) {
        throw new Error(`Unknown provider: ${providerId}`);
    }

    try {
        const apiKey = await getSecret(provider.secretKey);
        if (!apiKey) {
            return {
                provider: providerId,
                status: 'not_configured',
                message: `API key not set. Add secret: ${provider.secretKey}`
            };
        }

        // Simple test request
        const startTime = Date.now();
        const response = await callProvider(providerId, provider.models[0].id, {
            prompt: 'Say "OK" and nothing else.',
            maxTokens: 10
        });

        return {
            provider: providerId,
            status: 'healthy',
            latencyMs: Date.now() - startTime,
            model: provider.models[0].id,
            response: response.content.substring(0, 50)
        };

    } catch (error) {
        return {
            provider: providerId,
            status: 'error',
            message: error.message
        };
    }
}

/**
 * Test all configured providers
 */
export async function testAllProviders() {
    await requireAdmin();

    const results = {};
    for (const providerId of Object.keys(PROVIDER_REGISTRY)) {
        results[providerId] = await testProvider(providerId);
    }
    return results;
}


