import { getSecret } from 'wix-secrets-backend';
import { fetch } from 'wix-fetch';
import * as dataAccess from 'backend/dataAccess';
import { getCarrierSafetyData } from 'backend/fmcsaService';
import { log, logAIOperation, startTrace, endTrace } from 'backend/observabilityService';

// ============================================================================
// CONFIGURATION - PRODUCTION-HARDENED 2025 STACK
// ============================================================================
const CONFIG = {
  // Collection keys (camelCase, matching configData.js)
  enrichmentsKey: 'carrierEnrichments',

  // Groq Configuration — LPU hardware, sub-second inference
  groqModel: 'llama-3.3-70b-versatile',
  groqSecret: 'GROQ',
  groqEndpoint: 'https://api.groq.com/openai/v1/chat/completions',
  groqTimeoutMs: 3000,

  // Claude Configuration — kept as fallback
  claudeModel: 'claude-haiku-4-5-20251001',
  claudeSecret: 'CLAUDE_API_KEY',
  claudeEndpoint: 'https://api.anthropic.com/v1/messages',

  // Gemini Configuration — Google Search grounding for real-time web research
  geminiModel: 'gemini-2.5-flash',
  geminiSecret: 'GEMINI_API_KEY',
  geminiEndpoint: 'https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent',
  geminiTimeoutMs: 5000,

  // Perplexity Configuration — kept as fallback (disabled)
  perplexityModel: 'sonar',
  perplexitySecret: 'PERPLEXITY_API_KEY',
  perplexityEndpoint: 'https://api.perplexity.ai/chat/completions',
  perplexityTimeoutMs: 4000,

  // Timeouts & Limits
  claudeTimeoutMs: 5000,
  maxTokens: 800,
  cacheExpiryDays: 14,

  // Feature Flags — Web research disabled for real-time (both Perplexity and Gemini
  // Search grounding take 5-8s+, always timing out). FMCSA + Groq produces solid
  // results in ~3s. Web research should be a nightly batch job instead.
  enableWebResearch: false,
  researchProvider: 'gemini', // 'gemini' or 'perplexity' (when enableWebResearch: true)
  fallbackToClaudeOnly: false
};

// ============================================================================
// SECRET CACHING (avoid repeated Wix Secrets lookups)
// ============================================================================
let __perplexityKeyCache = null;
let __claudeKeyCache = null;
let __groqKeyCache = null;
let __geminiKeyCache = null;
let __keyCacheTime = 0;
const KEY_CACHE_TTL = 3600000; // 1 hour

async function getCachedSecret(secretName) {
  const now = Date.now();
  if (secretName === CONFIG.perplexitySecret && __perplexityKeyCache && (now - __keyCacheTime < KEY_CACHE_TTL)) return __perplexityKeyCache;
  if (secretName === CONFIG.claudeSecret && __claudeKeyCache && (now - __keyCacheTime < KEY_CACHE_TTL)) return __claudeKeyCache;
  if (secretName === CONFIG.groqSecret && __groqKeyCache && (now - __keyCacheTime < KEY_CACHE_TTL)) return __groqKeyCache;
  if (secretName === CONFIG.geminiSecret && __geminiKeyCache && (now - __keyCacheTime < KEY_CACHE_TTL)) return __geminiKeyCache;
  const key = await getSecret(secretName);
  if (secretName === CONFIG.perplexitySecret) __perplexityKeyCache = key;
  if (secretName === CONFIG.claudeSecret) __claudeKeyCache = key;
  if (secretName === CONFIG.groqSecret) __groqKeyCache = key;
  if (secretName === CONFIG.geminiSecret) __geminiKeyCache = key;
  __keyCacheTime = now;
  return key;
}

// ============================================================================
// MAIN ENRICHMENT PIPELINE - FAULT TOLERANT
// ============================================================================

/**
 * @param {string} dotNumber
 * @param {Object} carrierData - Normalized carrier with UPPERCASE keys
 * @param {Object} driverPrefs
 * @param {string|null} socialIntel
 * @param {Object} [options] - Pipeline overrides
 * @param {boolean} [options.enableWebResearch] - Force web research on/off
 * @param {string}  [options.researchProvider] - 'perplexity' | 'gemini'
 * @param {number}  [options.budgetMs] - Override pipeline timeout
 * @param {boolean} [options.skipCache] - Ignore existing cache (force re-enrich)
 */
export async function enrichCarrier(dotNumber, carrierData, driverPrefs, socialIntel = null, options = {}) {
  const dot = String(dotNumber).trim();
  const startTime = Date.now();

  console.log(`[aiEnrichment] Starting enrichment for DOT ${dot}${options.enableWebResearch ? ' (with web research)' : ''}`);

  try {
    // FAST PATH: Check cache first (unless skipCache is set for batch re-enrichment)
    const traceId = 'tr_' + Date.now().toString(36) + '_' + Math.random().toString(36).slice(2, 8);

    if (!options.skipCache) {
      const cached = await getCachedSentiment(dot, traceId).catch(() => null);
      if (cached && !isSentimentStale(cached.enriched_date)) {
        console.log(`[aiEnrichment] Cache hit for DOT ${dot} (${cached.cache_age_days}d old, ${Date.now() - startTime}ms)`);
        return { ...cached, fmcsa: transformFMCSAForFrontend(null), fromCache: true };
      }
    }

    // Run full pipeline synchronously with timeout budget
    const ENRICHMENT_BUDGET_MS = options.budgetMs || 8000;
    console.log(`[aiEnrichment] No cache for DOT ${dot} — running pipeline with ${ENRICHMENT_BUDGET_MS / 1000}s budget`);

    const pipelineResult = await Promise.race([
      _runBackgroundEnrichment(dot, carrierData, driverPrefs, socialIntel, traceId, options)
        .then(result => ({ completed: true, ...result }))
        .catch(err => {
          console.error(`[aiEnrichment] Pipeline failed for DOT ${dot}:`, err.message);
          return null;
        }),
      new Promise(resolve =>
        setTimeout(() => resolve(null), ENRICHMENT_BUDGET_MS)
      )
    ]);

    if (pipelineResult?.completed) {
      console.log(`[aiEnrichment] Pipeline completed for DOT ${dot} in ${Date.now() - startTime}ms`);
      return { ...pipelineResult, fmcsa: transformFMCSAForFrontend(null), fromCache: false };
    }

    // Timed out or failed — return fallback
    console.log(`[aiEnrichment] Pipeline timed out for DOT ${dot} (${Date.now() - startTime}ms)`);
    return {
      ...generateFallbackEnrichment(dot, carrierData, driverPrefs, 'AI profile unavailable', transformFMCSAForFrontend(null)),
      building: false
    };

  } catch (error) {
    console.error(`[aiEnrichment] enrichCarrier error for DOT ${dot}:`, error.message);
    return generateFallbackEnrichment(dot, carrierData, driverPrefs, error.message, transformFMCSAForFrontend(null));
  }
}

/**
 * Background enrichment — runs after we've already returned to the caller.
 * Writes result to cache so the next "Retry" request gets the real data.
 */
async function _runBackgroundEnrichment(dot, carrierData, driverPrefs, socialIntel, traceId, options = {}) {
  const startTime = Date.now();

  startTrace('enrichCarrier', {
    dotNumber: dot,
    hasSocialIntel: !!socialIntel,
    tags: ['ai-enrichment', 'background'],
    traceId
  }).catch(() => {});

  // PARALLEL PHASE: FMCSA + Web Research (Gemini or Perplexity)
  const carrierName = carrierData.LEGAL_NAME || carrierData.DBA_NAME || 'Unknown Carrier';
  const carrierLocation = `${carrierData.PHY_CITY || ''}, ${carrierData.PHY_STATE || ''}`;

  // Options can override web research settings (used by nightly batch)
  const doWebResearch = options.enableWebResearch !== undefined ? options.enableWebResearch : CONFIG.enableWebResearch;
  const provider = options.researchProvider || CONFIG.researchProvider;

  // Nightly batch gets generous 30s timeout; real-time uses CONFIG defaults
  const researchTimeoutMs = options.budgetMs ? 30000 : null;

  const researchFn = doWebResearch
    ? (provider === 'gemini'
        ? fetchGeminiResearchWithTimeout(carrierName, carrierLocation, traceId, researchTimeoutMs)
        : fetchPerplexityResearchWithTimeout(carrierName, carrierLocation, traceId, researchTimeoutMs))
    : Promise.resolve('');

  const [fmcsaResult, researchResult] = await Promise.allSettled([
    getCarrierSafetyData(dot).catch(err => {
      console.error(`[aiEnrichment] FMCSA failed for ${dot}:`, err.message);
      return { error: true, error_message: "FMCSA Service Unavailable" };
    }),
    researchFn
  ]);

  const fmcsaData = fmcsaResult.status === 'fulfilled' ? fmcsaResult.value : { error: true };
  const rawResearch = researchResult.status === 'fulfilled' ? researchResult.value : '';

  // SYNTHESIS: Groq LPU (sub-second inference) with Claude fallback
  const { systemPrompt, userPrompt } = buildGroundedPrompt(carrierData, driverPrefs, fmcsaData, socialIntel);
  const combinedResearch = (rawResearch + "\n\n" + (socialIntel || "")).trim();

  let enrichedData;
  try {
    enrichedData = await callGroqSynthesisWithTimeout(systemPrompt, userPrompt, combinedResearch, dot, traceId);
  } catch (groqErr) {
    console.warn(`[aiEnrichment] Groq failed for DOT ${dot}: ${groqErr.message} — falling back to Claude`);
    enrichedData = await callClaudeSynthesisWithTimeout(systemPrompt, userPrompt, combinedResearch, dot, traceId);
  }

  // Fire-and-forget cache write — don't block the response
  cacheSentimentEnrichment(enrichedData, traceId).catch(() => {});

  const elapsed = Date.now() - startTime;
  console.log(`[aiEnrichment] Background enrichment complete for DOT ${dot} in ${elapsed}ms`);

  endTrace(traceId, 'completed', { elapsed, dot }).catch(() => {});

  return enrichedData;
}

// ============================================================================
// STAGE 1: GEMINI WEB RESEARCH (Google Search Grounding)
// ============================================================================

async function fetchGeminiResearchWithTimeout(carrierName, carrierLocation, traceId = null, timeoutOverrideMs = null) {
  const apiStartTime = Date.now();
  const timeoutMs = timeoutOverrideMs || CONFIG.geminiTimeoutMs;

  try {
    const apiKey = await getCachedSecret(CONFIG.geminiSecret);
    if (!apiKey) {
      console.warn('[aiEnrichment] Gemini API key not configured — falling back to Perplexity');
      return fetchPerplexityResearchWithTimeout(carrierName, carrierLocation, traceId, timeoutOverrideMs);
    }

    console.log(`[aiEnrichment] Gemini: Researching "${carrierName}" with Google Search (${timeoutMs / 1000}s timeout)`);

    const timeoutPromise = new Promise((_, reject) => {
      setTimeout(() => reject(new Error('Gemini timeout')), timeoutMs);
    });

    const fetchPromise = fetch(`${CONFIG.geminiEndpoint}?key=${apiKey}`, {
      method: 'POST',
      headers: { 'Content-Type': 'application/json' },
      body: JSON.stringify({
        contents: [{
          role: 'user',
          parts: [{ text: `Research CDL truck driver jobs at "${carrierName}" (${carrierLocation}). Find: current CPM pay range, any sign-on bonuses, typical home time, freight types, and 2-3 recent driver reviews or sentiment. Focus on 2025-2026 data. Be concise, max 300 words.` }]
        }],
        tools: [{ google_search: {} }],
        generationConfig: {
          maxOutputTokens: 600,
          temperature: 0.2
        }
      })
    });

    const response = await Promise.race([fetchPromise, timeoutPromise]);
    const latencyMs = Date.now() - apiStartTime;

    if (!response.ok) {
      const errBody = await response.text().catch(() => '');
      console.warn(`[aiEnrichment] Gemini API Error: ${response.status} — ${errBody.slice(0, 200)}`);
      logAIOperation({
        source: 'ai-enrichment', operation: 'research', functionId: 'gemini-research',
        provider: 'google', model: CONFIG.geminiModel, latencyMs,
        error: `HTTP ${response.status}`, traceId
      }).catch(() => {});
      return generateInternalResearchFallback(carrierName);
    }

    const result = await response.json();
    const content = result.candidates?.[0]?.content?.parts?.[0]?.text || '';

    console.log(`[aiEnrichment] Gemini returned ${content.length} chars in ${latencyMs}ms`);

    logAIOperation({
      source: 'ai-enrichment', operation: 'research', functionId: 'gemini-research',
      provider: 'google', model: CONFIG.geminiModel, latencyMs, traceId
    }).catch(() => {});

    return content;

  } catch (e) {
    const latencyMs = Date.now() - apiStartTime;
    if (e.message === 'Gemini timeout') {
      console.warn(`[aiEnrichment] Gemini timed out after ${timeoutMs}ms — using fallback`);
    } else {
      console.error('[aiEnrichment] Gemini fetch failed:', e.message);
    }
    logAIOperation({
      source: 'ai-enrichment', operation: 'research', functionId: 'gemini-research',
      provider: 'google', model: CONFIG.geminiModel, latencyMs,
      error: e.message, traceId
    }).catch(() => {});
    return generateInternalResearchFallback(carrierName);
  }
}

// ============================================================================
// STAGE 1b: PERPLEXITY RESEARCHER (legacy fallback)
// ============================================================================

async function fetchPerplexityResearchWithTimeout(carrierName, carrierLocation, traceId = null, timeoutOverrideMs = null) {
  const apiStartTime = Date.now();
  const timeoutMs = timeoutOverrideMs || CONFIG.perplexityTimeoutMs;

  try {
    const apiKey = await getCachedSecret(CONFIG.perplexitySecret);
    if (!apiKey) {
      console.warn('[aiEnrichment] Perplexity API key not configured');
      return generateInternalResearchFallback(carrierName);
    }

    console.log(`[aiEnrichment] Perplexity: Researching "${carrierName}" (${timeoutMs / 1000}s timeout)`);

    const timeoutPromise = new Promise((_, reject) => {
      setTimeout(() => reject(new Error('Perplexity timeout')), timeoutMs);
    });

    const fetchPromise = fetch(CONFIG.perplexityEndpoint, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`,
        'Content-Type': 'application/json'
      },
      body: JSON.stringify({
        // Use sonar-pro for nightly batch (thorough), sonar for real-time (fast)
        model: timeoutMs >= 10000 ? 'sonar-pro' : CONFIG.perplexityModel,
        messages: [
          {
            role: "system",
            content: "You are a trucking industry researcher. Provide factual, concise information about carrier jobs. Include source citations as [1], [2] etc. Be brief - max 300 words."
          },
          {
            role: "user",
            content: `Research CDL driver jobs at "${carrierName}" (${carrierLocation}). Find: current CPM pay range, any sign-on bonuses, typical home time, freight types, and 2-3 driver reviews or sentiment. Focus on 2025-2026 data only.`
          }
        ],
        max_tokens: 600,
        temperature: 0.2
      })
    });

    const response = await Promise.race([fetchPromise, timeoutPromise]);
    const latencyMs = Date.now() - apiStartTime;

    if (!response.ok) {
      console.warn(`[aiEnrichment] Perplexity API Error: ${response.status}`);
      logAIOperation({
        source: 'ai-enrichment',
        operation: 'research',
        functionId: 'perplexity-research',
        provider: 'perplexity',
        model: CONFIG.perplexityModel,
        latencyMs,
        error: `HTTP ${response.status}`,
        traceId
      }).catch(() => {});
      return generateInternalResearchFallback(carrierName);
    }

    const result = await response.json();
    const content = result.choices?.[0]?.message?.content || '';
    const usage = result.usage || {};

    console.log(`[aiEnrichment] Perplexity returned ${content.length} chars`);

    // Log successful AI operation
    logAIOperation({
      source: 'ai-enrichment',
      operation: 'research',
      functionId: 'perplexity-research',
      provider: 'perplexity',
      model: CONFIG.perplexityModel,
      inputTokens: usage.prompt_tokens,
      outputTokens: usage.completion_tokens,
      totalTokens: usage.total_tokens,
      latencyMs,
      traceId
    }).catch(() => {});

    return content;

  } catch (e) {
    const latencyMs = Date.now() - apiStartTime;
    if (e.message === 'Perplexity timeout') {
      console.warn(`[aiEnrichment] Perplexity timed out after ${timeoutMs}ms - using fallback`);
    } else {
      console.error("[aiEnrichment] Perplexity fetch failed:", e.message);
    }
    logAIOperation({
      source: 'ai-enrichment',
      operation: 'research',
      functionId: 'perplexity-research',
      provider: 'perplexity',
      model: CONFIG.perplexityModel,
      latencyMs,
      error: e.message,
      traceId
    }).catch(() => {});
    return generateInternalResearchFallback(carrierName);
  }
}

function generateInternalResearchFallback(carrierName) {
  return `Web research unavailable for ${carrierName}. Please infer typical industry standards for a carrier of this profile based on fleet size, location, and operation type. Note that specific pay rates and reviews could not be verified from external sources.`;
}

// ============================================================================
// STAGE 2: CLAUDE PROMPT BUILDER
// ============================================================================

function buildGroundedPrompt(carrierData, driverPrefs, fmcsaData, socialIntel) {
  const carrierName = fmcsaData?.legal_name || carrierData.LEGAL_NAME || 'Unknown';
  const safetyRating = fmcsaData?.safety_rating || 'NOT RATED';
  const fleetSize = fmcsaData?.total_power_units || carrierData?.NBR_POWER_UNIT || 0;
  const driverCount = fmcsaData?.total_drivers || carrierData?.DRIVER_TOTAL || 0;

  // Determine fleet category
  let fleetCategory = 'small';
  if (fleetSize >= 500) fleetCategory = 'large';
  else if (fleetSize >= 50) fleetCategory = 'medium';

  const systemPrompt = `You are the Lead Data Analyst for LMDR (Last Mile Driver Recruiting).
  Your job is to create concise, actionable intelligence summaries for CDL drivers evaluating carriers.
  CORE RULES:
  1. FMCSA safety data provided is VERIFIED TRUTH. Never contradict it.
  2. Extract pay rates, sentiment, and job details from web research when available.
  3. If "SOCIAL MEDIA INTEL" is provided, prioritize those unfiltered driver opinions for 'driver_sentiment' and 'pros/cons'.
  4. Be honest about confidence levels - mark inferred data clearly.
  5. Output ONLY valid JSON.
  6. Keep the ai_summary to 2-3 sentences max.`;

  // Inject Social Intel if present
  let socialContext = "";
  if (socialIntel && socialIntel.length > 10) {
    socialContext = `
    SOCIAL MEDIA INTEL (Reddit/Twitter/Forums):
    "${socialIntel}"
    (Use this strictly for sentiment, pros/cons, and culture analysis. It is raw and unfiltered.)
    `;
  }

  // Carrier intelligence scores (from Carriers Master — higher = better, 0-100 scale)
  const payCPM = carrierData?.PAY_CPM || 0;
  const turnoverPct = carrierData?.TURNOVER_PERCENT || 0;
  const accidentRate = carrierData?.ACCIDENT_RATE || 0;
  const avgTruckAge = carrierData?.AVG_TRUCK_AGE || 0;
  const combinedScore = carrierData?.COMBINED_SCORE || 0;
  const recruitmentScore = carrierData?.RECRUITMENT_SCORE || 0;
  const operationType = carrierData?.CARRIER_OPERATION || 'Unknown';
  const recentMileage = carrierData?.RECENT_MILEAGE || 0;

  const userPrompt = `VERIFIED FMCSA DATA (treat as ground truth):
  - Carrier Name: ${carrierName}
  - DOT Number: ${fmcsaData?.dot_number || 'Unknown'}
  - Safety Rating: ${safetyRating}
  - Fleet Size: ${fleetSize} power units (${fleetCategory} fleet)
  - Driver Count: ${driverCount}
  - Location: ${fmcsaData?.phy_city || carrierData?.PHY_CITY || 'Unknown'}, ${fmcsaData?.phy_state || carrierData?.PHY_STATE || 'Unknown'}
  - Operation Type: ${operationType}

  CARRIER INTELLIGENCE SCORES (proprietary analysis):
  - Pay Rate: ${payCPM > 0 ? '$' + payCPM.toFixed(2) + ' CPM' : 'Not available'}
  - Combined Quality Score: ${combinedScore}/100 ${combinedScore >= 80 ? '(Excellent)' : combinedScore >= 60 ? '(Good)' : combinedScore >= 40 ? '(Average)' : '(Below Average)'}
  - Recruitment Score: ${recruitmentScore}/100 ${recruitmentScore >= 70 ? '(Actively recruiting)' : '(Low recruiting activity)'}
  - Driver Turnover: ${turnoverPct > 0 ? turnoverPct + '%' : 'Not available'} ${turnoverPct > 0 && turnoverPct < 50 ? '(Good retention)' : turnoverPct >= 80 ? '(High turnover - red flag)' : ''}
  - Accident Rate: ${accidentRate > 0 ? accidentRate.toFixed(2) : 'Not available'}
  - Average Truck Age: ${avgTruckAge > 0 ? avgTruckAge.toFixed(1) + ' years' : 'Not available'} ${avgTruckAge > 0 && avgTruckAge <= 3 ? '(New fleet)' : avgTruckAge > 5 ? '(Aging fleet)' : ''}
  - Recent Mileage: ${recentMileage > 0 ? recentMileage.toLocaleString() + ' miles' : 'Not available'}

  ${socialContext}

  DRIVER PREFERENCES:
  - Looking for: ${driverPrefs?.operationType || 'Any'} runs
  - Min CPM: ${driverPrefs?.minCPM || 'Not specified'}

  OUTPUT THIS EXACT JSON STRUCTURE:
  {
    "freight_types": "List main freight types or 'General Freight'",
    "route_types": "OTR/Regional/Local/Dedicated",
    "home_time": "Weekly/Every 2-3 weeks/Varies",
    "pay_cpm_range": "Format as '$X.XX-$X.XX CPM' or 'Market rate'",
    "sign_on_bonus": "Specific amount or 'None advertised'",
    "benefits": "Health, 401k, PTO details or 'Standard benefits package'",
    "hiring_status": "Actively Hiring/Unknown/Contact Carrier",
    "driver_sentiment": "Positive/Mixed/Negative - Base on Social Intel if available",
    "sentiment_pros": ["Positive 1", "Positive 2", "Positive 3"],
    "sentiment_cons": ["Concern 1", "Concern 2", "Concern 3"],
    "sources_found": ["List specific forums if in Social Intel, otherwise 'Web Search'"],
    "data_confidence": "High/Medium/Low",
    "ai_summary": "2-3 sentence summary combining safety record + social rumors + job appeal"
  }`;

  return { systemPrompt, userPrompt };
}

// ============================================================================
// STAGE 3: GROQ LPU SYNTHESIS ENGINE (PRIMARY)
// ============================================================================

async function callGroqSynthesisWithTimeout(system, user, research, dotNumber, traceId = null) {
  const apiStartTime = Date.now();

  const apiKey = await getCachedSecret(CONFIG.groqSecret);
  if (!apiKey) {
    throw new Error('Groq API key not configured');
  }

  console.log(`[aiEnrichment] Groq: Synthesizing enrichment for DOT ${dotNumber}`);

  const researchContext = research && research.length > 50
    ? `\n\nWEB RESEARCH & SOCIAL FINDINGS:\n${research}`
    : '\n\nNOTE: Limited web research available. Use industry knowledge to make reasonable inferences.';

  const timeoutPromise = new Promise((_, reject) => {
    setTimeout(() => reject(new Error('Groq timeout')), CONFIG.groqTimeoutMs);
  });

  const fetchPromise = fetch(CONFIG.groqEndpoint, {
    method: 'POST',
    headers: {
      'Authorization': `Bearer ${apiKey}`,
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: CONFIG.groqModel,
      messages: [
        { role: 'system', content: system },
        { role: 'user', content: `${user}${researchContext}` }
      ],
      max_tokens: CONFIG.maxTokens,
      temperature: 0.3
    })
  });

  try {
    const response = await Promise.race([fetchPromise, timeoutPromise]);
    const latencyMs = Date.now() - apiStartTime;

    if (!response.ok) {
      const errorText = await response.text().catch(() => 'No error details');
      logAIOperation({
        source: 'ai-enrichment',
        operation: 'synthesis',
        functionId: 'groq-synthesis',
        provider: 'groq',
        model: CONFIG.groqModel,
        latencyMs,
        error: `HTTP ${response.status}: ${errorText}`,
        traceId
      }).catch(() => {});
      throw new Error(`Groq API Error: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    const responseText = data.choices?.[0]?.message?.content || '';
    const usage = data.usage || {};

    console.log(`[aiEnrichment] Groq returned ${responseText.length} chars in ${latencyMs}ms`);

    logAIOperation({
      source: 'ai-enrichment',
      operation: 'synthesis',
      functionId: 'groq-synthesis',
      provider: 'groq',
      model: CONFIG.groqModel,
      inputTokens: usage.prompt_tokens,
      outputTokens: usage.completion_tokens,
      totalTokens: usage.total_tokens,
      latencyMs,
      traceId
    }).catch(() => {});

    return parseSentimentResponse(responseText, dotNumber);

  } catch (error) {
    const latencyMs = Date.now() - apiStartTime;
    logAIOperation({
      source: 'ai-enrichment',
      operation: 'synthesis',
      functionId: 'groq-synthesis',
      provider: 'groq',
      model: CONFIG.groqModel,
      latencyMs,
      error: error.message,
      traceId
    }).catch(() => {});
    throw error;
  }
}

// ============================================================================
// STAGE 3b: CLAUDE SYNTHESIS ENGINE (FALLBACK)
// ============================================================================

async function callClaudeSynthesisWithTimeout(system, user, research, dotNumber, traceId = null) {
  const apiStartTime = Date.now();

  const apiKey = await getCachedSecret(CONFIG.claudeSecret);
  if (!apiKey) {
    throw new Error('Claude API key not configured');
  }

  console.log(`[aiEnrichment] Claude: Synthesizing enrichment for DOT ${dotNumber}`);

  const researchContext = research && research.length > 50
    ? `\n\nWEB RESEARCH & SOCIAL FINDINGS:\n${research}`
    : '\n\nNOTE: Limited web research available. Use industry knowledge to make reasonable inferences.';

  const timeoutPromise = new Promise((_, reject) => {
    setTimeout(() => reject(new Error('Claude timeout')), CONFIG.claudeTimeoutMs);
  });

  const fetchPromise = fetch(CONFIG.claudeEndpoint, {
    method: 'POST',
    headers: {
      'x-api-key': apiKey,
      'anthropic-version': '2023-06-01',
      'Content-Type': 'application/json'
    },
    body: JSON.stringify({
      model: CONFIG.claudeModel,
      max_tokens: CONFIG.maxTokens,
      system: system,
      messages: [{
        role: 'user',
        content: `${user}${researchContext}`
      }]
    })
  });

  try {
    const response = await Promise.race([fetchPromise, timeoutPromise]);
    const latencyMs = Date.now() - apiStartTime;

    if (!response.ok) {
      const errorText = await response.text().catch(() => 'No error details');
      logAIOperation({
        source: 'ai-enrichment',
        operation: 'synthesis',
        functionId: 'claude-synthesis',
        provider: 'anthropic',
        model: CONFIG.claudeModel,
        latencyMs,
        error: `HTTP ${response.status}: ${errorText}`,
        traceId
      }).catch(() => {});
      throw new Error(`Claude API Error: ${response.status} - ${errorText}`);
    }

    const data = await response.json();
    const responseText = extractTextFromResponse(data);
    const usage = data.usage || {};

    console.log(`[aiEnrichment] Claude returned ${responseText.length} chars`);

    // Log successful AI operation
    logAIOperation({
      source: 'ai-enrichment',
      operation: 'synthesis',
      functionId: 'claude-synthesis',
      provider: 'anthropic',
      model: CONFIG.claudeModel,
      inputTokens: usage.input_tokens,
      outputTokens: usage.output_tokens,
      totalTokens: (usage.input_tokens || 0) + (usage.output_tokens || 0),
      latencyMs,
      traceId
    }).catch(() => {});

    return parseSentimentResponse(responseText, dotNumber);

  } catch (error) {
    const latencyMs = Date.now() - apiStartTime;
    logAIOperation({
      source: 'ai-enrichment',
      operation: 'synthesis',
      functionId: 'claude-synthesis',
      provider: 'anthropic',
      model: CONFIG.claudeModel,
      latencyMs,
      error: error.message,
      traceId
    }).catch(() => {});
    throw error;
  }
}

// ============================================================================
// UTILITIES - RESPONSE PARSING
// ============================================================================

function transformFMCSAForFrontend(fmcsaData) {
  if (!fmcsaData) return createEmptyFMCSAObject();

  const inspections = fmcsaData.inspections || {};
  const crashes = fmcsaData.crashes || {};
  const basics = fmcsaData.basics || {};

  return {
    dot_number: fmcsaData.dot_number,
    legal_name: fmcsaData.legal_name,
    dba_name: fmcsaData.dba_name,
    operating_status: fmcsaData.operating_status,
    is_authorized: fmcsaData.is_authorized,
    safety_rating: fmcsaData.safety_rating || 'UNKNOWN',
    safety_rating_code: fmcsaData.safety_rating_code,
    safety_rating_date: fmcsaData.safety_rating_date,
    total_drivers: fmcsaData.total_drivers,
    total_power_units: fmcsaData.total_power_units,

    inspections_24mo: {
      total: (inspections.driver_inspections || 0) + (inspections.vehicle_inspections || 0),
      driver_inspections: inspections.driver_inspections || 0,
      vehicle_inspections: inspections.vehicle_inspections || 0,
      driver_oos_rate: inspections.driver_oos_rate,
      vehicle_oos_rate: inspections.vehicle_oos_rate,
      national_avg_driver_oos: inspections.national_avg_driver_oos || 5.51,
      national_avg_vehicle_oos: inspections.national_avg_vehicle_oos || 20.72
    },

    crashes_24mo: {
      total: crashes.total || 0,
      fatal: crashes.fatal || 0,
      injury: crashes.injury || 0,
      tow: crashes.tow || 0
    },

    basics: basics,
    has_basic_alerts: fmcsaData.has_basic_alerts || false,
    fetched_date: fmcsaData.fetched_date,
    data_source: fmcsaData.data_source || 'FMCSA_SAFER_API',
    fromCache: fmcsaData.fromCache || false,
    cache_age_days: fmcsaData.cache_age_days,
    error: fmcsaData.error || false,
    error_message: fmcsaData.error_message
  };
}

function createEmptyFMCSAObject() {
  return {
    dot_number: null,
    safety_rating: 'UNKNOWN',
    inspections_24mo: { total: 0, driver_oos_rate: null, vehicle_oos_rate: null },
    crashes_24mo: { total: 0, fatal: 0 },
    error: true
  };
}

function extractTextFromResponse(data) {
  if (!data.content || !Array.isArray(data.content)) return '';
  return data.content
    .filter(block => block.type === 'text')
    .map(block => block.text)
    .join('\n')
    .trim();
}

function parseSentimentResponse(responseText, dotNumber) {
  try {
    let jsonStr = responseText.trim();
    // Strip markdown code blocks if present
    const jsonMatch = jsonStr.match(/```(?:json)?\s*([\s\S]*?)\s*```/);
    if (jsonMatch) jsonStr = jsonMatch[1].trim();

    // Find JSON object
    const jsonObjectMatch = jsonStr.match(/\{[\s\S]*\}/);
    if (jsonObjectMatch) jsonStr = jsonObjectMatch[0];

    const parsed = JSON.parse(jsonStr);

    return {
      dot_number: String(dotNumber),
      freight_types: parsed.freight_types || 'General Freight',
      route_types: parsed.route_types || 'Regional/OTR',
      home_time: parsed.home_time || 'Contact Carrier',
      pay_cpm_range: parsed.pay_cpm_range || 'Market Rate',
      sign_on_bonus: parsed.sign_on_bonus || 'Contact Carrier',
      benefits: parsed.benefits || 'Standard Package',
      hiring_status: parsed.hiring_status || 'Unknown',
      driver_sentiment: parsed.driver_sentiment || 'No Reviews',
      sentiment_pros: JSON.stringify(parsed.sentiment_pros || []),
      sentiment_cons: JSON.stringify(parsed.sentiment_cons || []),
      sources_found: JSON.stringify(parsed.sources_found || ['FMCSA SAFER']),
      data_confidence: parsed.data_confidence || 'Low',
      ai_summary: parsed.ai_summary || 'Limited data available. Contact carrier for details.',
      enriched_date: new Date(),
      enrichment_version: 10,
      source: 'groq-perplexity-hybrid-v4'
    };
  } catch (parseError) {
    console.error('[aiEnrichment] Failed to parse Claude response:', parseError.message);
    return {
      dot_number: String(dotNumber),
      ai_summary: "AI analysis incomplete. Please check FMCSA records and contact carrier directly.",
      driver_sentiment: "Unavailable",
      data_confidence: "None",
      error: true,
      enriched_date: new Date(),
      enrichment_version: 10
    };
  }
}

// ============================================================================
// CACHE MANAGEMENT
// ============================================================================

async function getCachedSentiment(dotNumber, traceId = null) {
  try {
    const result = await dataAccess.queryRecords(CONFIG.enrichmentsKey, {
      filters: { dot_number: String(dotNumber) },
      limit: 1,
      traceId
    });

    const items = result.items || [];
    if (items.length === 0) return null;

    const cached = items[0];
    const enrichedDate = cached.enriched_date ? new Date(cached.enriched_date) : null;
    const ageInDays = enrichedDate
      ? (Date.now() - enrichedDate.getTime()) / (1000 * 60 * 60 * 24)
      : 999;

    return { ...cached, cache_age_days: Math.round(ageInDays * 10) / 10 };
  } catch (error) {
    console.error('[aiEnrichment] Cache lookup error:', error.message);
    return null;
  }
}

function isSentimentStale(enrichedDate) {
  if (!enrichedDate) return true;
  const daysSince = (Date.now() - new Date(enrichedDate).getTime()) / (1000 * 60 * 60 * 24);
  return daysSince > CONFIG.cacheExpiryDays;
}

async function cacheSentimentEnrichment(sentimentData, traceId = null) {
  try {
    const dataToCache = { ...sentimentData };
    delete dataToCache.fmcsa; // FMCSA is cached separately

    const existing = await getCachedSentiment(sentimentData.dot_number, traceId);

    if (existing && existing._id) {
      await dataAccess.updateRecord(CONFIG.enrichmentsKey, {
        ...dataToCache,
        _id: existing._id,
        match_count: (existing.match_count || 0) + 1,
        last_matched_date: new Date()
      }, { traceId });
      console.log(`[aiEnrichment] Updated cached enrichment for DOT ${sentimentData.dot_number}`);
    } else {
      await dataAccess.insertRecord(CONFIG.enrichmentsKey, {
        ...dataToCache,
        match_count: 1,
        last_matched_date: new Date()
      }, { traceId });
      console.log(`[aiEnrichment] Created new cached enrichment for DOT ${sentimentData.dot_number}`);
    }
  } catch (error) {
    console.error('[aiEnrichment] Failed to cache enrichment:', error.message);
  }
}

// ============================================================================
// FALLBACK ENRICHMENT
// ============================================================================

function generateFallbackEnrichment(dotNumber, carrierData, driverPrefs, errorMessage, fmcsaData) {
  const carrierName = carrierData?.LEGAL_NAME || fmcsaData?.legal_name || 'This carrier';
  const city = carrierData?.PHY_CITY || fmcsaData?.phy_city || 'their location';
  const state = carrierData?.PHY_STATE || fmcsaData?.phy_state || '';
  const fleetSize = carrierData?.NBR_POWER_UNIT || fmcsaData?.total_power_units || 0;

  let inferredRouteType = 'Regional/OTR';
  if (fleetSize < 20) inferredRouteType = 'Regional/Local';
  else if (fleetSize > 200) inferredRouteType = 'OTR/Dedicated';

  return {
    dot_number: String(dotNumber),
    freight_types: 'General Freight',
    route_types: inferredRouteType,
    home_time: 'Contact Carrier',
    pay_cpm_range: 'Market Rate ($0.55-0.70)',
    sign_on_bonus: 'Contact for current offers',
    benefits: 'Contact for details',
    hiring_status: 'Contact Carrier',
    driver_sentiment: 'No reviews available',
    sentiment_pros: JSON.stringify([]),
    sentiment_cons: JSON.stringify([]),
    sources_found: JSON.stringify(['FMCSA SAFER']),
    data_confidence: 'Low',
    ai_summary: `${carrierName} is a ${fleetSize > 0 ? fleetSize + '-truck' : ''} carrier based in ${city}${state ? ', ' + state : ''}. AI research was temporarily unavailable. Check FMCSA safety records above and contact the carrier directly for job details.`,
    fmcsa: fmcsaData,
    error: true,
    errorMessage: errorMessage,
    enriched_date: new Date(),
    enrichment_version: 9
  };
}
